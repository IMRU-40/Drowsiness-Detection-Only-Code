{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver Drowsiness Detection System\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import dlib\n",
    "import cv2\n",
    "import multiprocessing\n",
    "from math import hypot\n",
    "from playsound import playsound\n",
    "\n",
    "\n",
    "class Project:\n",
    "    def __init__(self):     # Constructor\n",
    "        self.p = multiprocessing.Process()\n",
    "\n",
    "    def soundOn(self):      # Play Sound\n",
    "        if not self.p.is_alive():\n",
    "            self.p = multiprocessing.Process(target=playsound, args=(\"alarm.mp3\",))\n",
    "            self.p.start()\n",
    "\n",
    "    def soundOff(self):     # Stop Sound\n",
    "        if self.p.is_alive():\n",
    "            self.p.terminate()\n",
    "\n",
    "    def aspect_ratio(self, landmark_list, face_landmark):   # Calculate Aspect Ratio\n",
    "        n = len(landmark_list)\n",
    "        left_point = (face_landmark.part(landmark_list[0]).x, face_landmark.part(landmark_list[0]).y)\n",
    "        right_point = (face_landmark.part(landmark_list[n//2]).x, face_landmark.part(landmark_list[n//2]).y)\n",
    "        # Calculate Horizontal Length\n",
    "        hor_length = hypot((left_point[0] - right_point[0]), (left_point[1] - right_point[1]))\n",
    "\n",
    "        top = list()    # Co-ordinates of the upper part    \n",
    "        bottom = list() # Co-ordinates of the lower part \n",
    "\n",
    "        for i in range(1, n//2):\n",
    "            top.append((face_landmark.part(landmark_list[i]).x, face_landmark.part(landmark_list[i]).y))\n",
    "            bottom.append((face_landmark.part(landmark_list[-1*i]).x, face_landmark.part(landmark_list[-1*i]).y))\n",
    "\n",
    "        ver_lengths = list()\n",
    "        for i in range(len(top)):   # Calculate vertical lengths\n",
    "            ver_lengths.append(hypot((top[i][0] - bottom[i][0]), (top[i][1] - bottom[i][1])))\n",
    "\n",
    "        s = len(ver_lengths)\n",
    "        ratio = sum(ver_lengths) / (s * hor_length) # Calculate aspect ratio\n",
    "        return ratio\n",
    "\n",
    "    def drowsinessDetectionSystem(self, video_path = 0):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        detector = dlib.get_frontal_face_detector()\n",
    "        predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "        eye_close_count = 0\n",
    "        mouth_open_count = 0\n",
    "        font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "        yawn_count = 0\n",
    "        yawning = False\n",
    "        drowsy_count = 0 \n",
    "        drowsy = False\n",
    "\n",
    "        max_ear = 0\n",
    "        min_ear = 1\n",
    "        per = 35\n",
    "        threshold_ear = 0.25\n",
    "        threshold_mar = 0.35\n",
    "        max_frame_count = 20\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:     # If no frame is detected then stop\n",
    "                break\n",
    "\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # Convert the image to gray scale\n",
    "            faces = detector(gray)  # Detect faces and get the co-ordinates of the rectangle where face is detected\n",
    "\n",
    "            if 0 < len(faces):\n",
    "                face = faces[0]     # Consider only 1st detected face\n",
    "                face_landmark = predictor(gray, face)   # Get facial landmarks\n",
    "\n",
    "                left_eye_ratio = self.aspect_ratio(list(range(36, 42)), face_landmark) # 2vertical 1horizontal\n",
    "                right_eye_ratio = self.aspect_ratio(list(range(42, 48)), face_landmark) # 2v 1h\n",
    "                eye_aspect_ratio = (left_eye_ratio + right_eye_ratio) / 2   # Calculate eye aspect ratio\n",
    "                cv2.putText(frame, \"Cur EAR: \"+str(round(eye_aspect_ratio, 5)), (10, 15), font, 0.5, (0, 0, 0))\n",
    "                cv2.putText(frame, \"Thresh EAR: \"+str(round(threshold_ear, 5)), (10, 30), font, 0.5, (0, 0, 0))\n",
    "\n",
    "                cv2.putText(frame, \"Drowsy Count: \"+str(drowsy_count), (250, 15), font, 0.5, (0, 0, 0))\n",
    "\n",
    "                inner_lip_ratio = self.aspect_ratio(list(range(60, 68)), face_landmark) # 3v  1h\n",
    "                outter_lip_ratio = self.aspect_ratio(list(range(48, 60)), face_landmark) # 5v 1h\n",
    "                mouth_aspect_ratio = (inner_lip_ratio + outter_lip_ratio) / 2 # Calculate mouth aspect ratio\n",
    "                cv2.putText(frame, \"Cur MAR: \"+str(round(mouth_aspect_ratio, 5)), (475, 15), font, 0.5, (0, 0, 0))\n",
    "                cv2.putText(frame, \"Thresh MAR: \"+str(round(threshold_mar, 5)), (475, 30), font, 0.5, (0, 0, 0))\n",
    "                cv2.putText(frame, \"Yawn Count: \"+str(yawn_count), (475, 45), font, 0.5, (0, 0, 0))\n",
    "\n",
    "                max_ear = max(max_ear, eye_aspect_ratio)\n",
    "                min_ear = min(min_ear, eye_aspect_ratio)\n",
    "                diff = max_ear - min_ear\n",
    "                threshold_ear = min_ear + diff * per / 100      # Calculate threshold eye aspect ratio\n",
    "\n",
    "                if eye_aspect_ratio < threshold_ear:\n",
    "                    eye_close_count += 1\n",
    "                else:\n",
    "                    eye_close_count = 0\n",
    "\n",
    "                if mouth_aspect_ratio > threshold_mar:\n",
    "                    mouth_open_count += 1\n",
    "                else:\n",
    "                    mouth_open_count = 0\n",
    "\n",
    "                # Get co-ordinates of rectangle in which face is detected\n",
    "                x1, y1 = face.left(), face.top()\n",
    "                x2, y2 = face.right(), face.bottom()\n",
    "\n",
    "                if eye_close_count >= max_frame_count:\n",
    "                    cv2.putText(frame, \"Eyes Closed\", (10, 55), font, 0.75, (0, 0, 255))\n",
    "                if mouth_open_count >= max_frame_count:\n",
    "                    cv2.putText(frame, \"Yawning\", (475, 70), font, 0.75, (0, 0, 255))\n",
    "                    if not yawning:\n",
    "                        yawn_count += 1\n",
    "                        yawning = True\n",
    "                else:\n",
    "                    if yawning:\n",
    "                        yawning = False\n",
    "\n",
    "                if eye_close_count < max_frame_count and mouth_open_count < max_frame_count:\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (31, 163, 21), 2)\n",
    "                    cv2.putText(frame, \"Active :)\", (250, 50), font, 1, (31, 163, 21))\n",
    "                    self.soundOff()\n",
    "                    if drowsy:\n",
    "                        drowsy = False\n",
    "                else:\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                    cv2.putText(frame, \"Drowsy!\", (250, 50), font, 1, (255, 0, 0))\n",
    "                    self.soundOn()\n",
    "                    if not drowsy:\n",
    "                        drowsy_count += 1\n",
    "                        drowsy = True\n",
    "\n",
    "                for i in range(0, 68):  # Plot 68 facial landmarks\n",
    "                    (x, y) = (face_landmark.part(i).x, face_landmark.part(i).y)\n",
    "                    cv2.circle(frame, (x, y), 1, (255, 255, 255), -1)\n",
    "\n",
    "            else:\n",
    "                self.soundOff()\n",
    "\n",
    "            cv2.imshow(\"Driver Drowsiness Detection System\", frame) # Display frame\n",
    "\n",
    "            key = cv2.waitKey(1)    # Press Esc to exit\n",
    "            if key == 27:\n",
    "                break\n",
    "\n",
    "        self.soundOff()\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "obj = Project()\n",
    "video_path = (input(\"Enter path of video: \") or 0)\n",
    "obj.drowsinessDetectionSystem(video_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import time\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import multiprocessing\n",
    "from math import hypot\n",
    "from playsound import playsound\n",
    "\n",
    "\n",
    "class Project:\n",
    "    def __init__(self):     # Constructor\n",
    "        self.p = multiprocessing.Process()\n",
    "\n",
    "    def soundOn(self):      # Play Sound\n",
    "        if not self.p.is_alive():\n",
    "            self.p = multiprocessing.Process(target=playsound, args=(\"alarm.mp3\",))\n",
    "            self.p.start()\n",
    "\n",
    "    def soundOff(self):     # Stop Sound\n",
    "        if self.p.is_alive():\n",
    "            self.p.terminate()\n",
    "\n",
    "    def aspect_ratio(self, landmark_list, face_landmark):   # Calculate Aspect Ratio\n",
    "        n = len(landmark_list)\n",
    "        left_point = (face_landmark[landmark_list[0]][0], face_landmark[landmark_list[0]][1]) # (x, y)\n",
    "        right_point = (face_landmark[landmark_list[n//2]][0], face_landmark[landmark_list[n//2]][1])\n",
    "        # print(landmark_list[0], landmark_list[n//2])\n",
    "        # Calculate Horizontal Length\n",
    "        hor_length = hypot((left_point[0] - right_point[0]), (left_point[1] - right_point[1]))\n",
    "\n",
    "        top = list()    # Co-ordinates of the upper part    \n",
    "        bottom = list() # Co-ordinates of the lower part \n",
    "        # t = list()    # Co-ordinates of the upper part    \n",
    "        # b = list() # Co-ordinates of the lower part \n",
    "\n",
    "        for i in range(1, n//2):\n",
    "            top.append((face_landmark[landmark_list[i]][0], face_landmark[landmark_list[i]][1]))\n",
    "            bottom.append((face_landmark[landmark_list[-1*i]][0], face_landmark[landmark_list[-1*i]][1]))\n",
    "            # t.append(landmark_list[i])\n",
    "            # b.append(landmark_list[-1*i])\n",
    "        # print(t)\n",
    "        # print(b)\n",
    "        ver_lengths = list()\n",
    "        for i in range(len(top)):   # Calculate vertical lengths\n",
    "            ver_lengths.append(hypot((top[i][0] - bottom[i][0]), (top[i][1] - bottom[i][1])))\n",
    "\n",
    "        s = len(ver_lengths)\n",
    "        ratio = sum(ver_lengths) / (s * hor_length) # Calculate aspect ratio\n",
    "        return ratio\n",
    "\n",
    "    def landmarkCoordinates(self, facelandmarks, image):\n",
    "        coord = list()\n",
    "        for lm in facelandmarks:\n",
    "            ih, iw, ic = image.shape # image height, image width, image channels\n",
    "            x, y = int(lm.x*iw), int(lm.y*ih)\n",
    "            coord.append((x, y))\n",
    "        return coord\n",
    "\n",
    "    def drowsinessDetectionSystem(self, video_path = 0):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        pTime = 0\n",
    "\n",
    "        mpFaceMesh = mp.solutions.face_mesh\n",
    "        faceMesh = mpFaceMesh.FaceMesh()\n",
    "        \n",
    "        eye_close_count = 0\n",
    "        mouth_open_count = 0\n",
    "        font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "        yawn_count = 0\n",
    "        yawning = False\n",
    "        drowsy_count = 0 \n",
    "        drowsy = False\n",
    "\n",
    "        max_ear = 0\n",
    "        min_ear = 1\n",
    "        per = 35\n",
    "        threshold_ear = 0.25\n",
    "        threshold_mar = 0.35\n",
    "        max_frame_count = 20\n",
    "\n",
    "        le = [33, 246, 161, 160, 159, 158, 157, 173,\n",
    "            133, 155, 154, 153, 145, 144, 163, 7]\n",
    "        re = [362, 398, 384, 385, 386, 387, 388, 466,\n",
    "            263, 249, 390, 373, 374, 380, 381, 382]\n",
    "\n",
    "        il = [78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "            308, 324, 318, 402, 317, 14, 87, 178, 88, 95]\n",
    "        ol = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n",
    "            291, 375, 321, 405, 314, 17, 84, 181, 91, 146]\n",
    "        \n",
    "        while True:\n",
    "            success, frame = cap.read()\n",
    "            if not success:     # If no frame is detected then stop\n",
    "                break\n",
    "\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            results = faceMesh.process(frame)  # Detect faces\n",
    "\n",
    "            cTime = time.time()\n",
    "            fps = 1/(cTime - pTime)\n",
    "            pTime = cTime\n",
    "            cv2.putText(frame, f\"FPS: {int(fps)}\", (10, 470), font, 0.5, (0,0,0))\n",
    "\n",
    "            if results.multi_face_landmarks:\n",
    "                face = results.multi_face_landmarks[0]     # Consider only 1st detected face\n",
    "                face_landmarks = self.landmarkCoordinates(face.landmark, frame)   # Get facial landmarks\n",
    "\n",
    "                left_eye_ratio = self.aspect_ratio(le, face_landmarks) # 7vertical 1horizontal\n",
    "                right_eye_ratio = self.aspect_ratio(re, face_landmarks) # 7v 1h\n",
    "                eye_aspect_ratio = (left_eye_ratio + right_eye_ratio) / 2   # Calculate eye aspect ratio\n",
    "                cv2.putText(frame, \"Cur EAR: \"+str(round(eye_aspect_ratio, 5)), (10, 15), font, 0.5, (0, 0, 0))\n",
    "                cv2.putText(frame, \"Thresh EAR: \"+str(round(threshold_ear, 5)), (10, 30), font, 0.5, (0, 0, 0))\n",
    "\n",
    "                cv2.putText(frame, \"Drowsy Count: \"+str(drowsy_count), (250, 15), font, 0.5, (0, 0, 0))\n",
    "\n",
    "                inner_lip_ratio = self.aspect_ratio(il, face_landmarks) # 9v  1h\n",
    "                outter_lip_ratio = self.aspect_ratio(ol, face_landmarks) # 9v 1h\n",
    "                mouth_aspect_ratio = (inner_lip_ratio + outter_lip_ratio) / 2 # Calculate mouth aspect ratio\n",
    "                cv2.putText(frame, \"Cur MAR: \"+str(round(mouth_aspect_ratio, 5)), (475, 15), font, 0.5, (0, 0, 0))\n",
    "                cv2.putText(frame, \"Thresh MAR: \"+str(round(threshold_mar, 5)), (475, 30), font, 0.5, (0, 0, 0))\n",
    "                cv2.putText(frame, \"Yawn Count: \"+str(yawn_count), (475, 45), font, 0.5, (0, 0, 0))\n",
    "\n",
    "                max_ear = max(max_ear, eye_aspect_ratio)\n",
    "                min_ear = min(min_ear, eye_aspect_ratio)\n",
    "                diff = max_ear - min_ear\n",
    "                threshold_ear = min_ear + diff * per / 100      # Calculate threshold eye aspect ratio\n",
    "\n",
    "                if eye_aspect_ratio < threshold_ear:\n",
    "                    eye_close_count += 1\n",
    "                else:\n",
    "                    eye_close_count = 0\n",
    "\n",
    "                if mouth_aspect_ratio > threshold_mar:\n",
    "                    mouth_open_count += 1\n",
    "                else:\n",
    "                    mouth_open_count = 0\n",
    "\n",
    "                if eye_close_count >= max_frame_count:\n",
    "                    cv2.putText(frame, \"Eyes Closed\", (10, 55), font, 0.75, (0, 0, 255))\n",
    "                if mouth_open_count >= max_frame_count:\n",
    "                    cv2.putText(frame, \"Yawning\", (475, 70), font, 0.75, (0, 0, 255))\n",
    "                    if not yawning:\n",
    "                        yawn_count += 1\n",
    "                        yawning = True\n",
    "                else:\n",
    "                    if yawning:\n",
    "                        yawning = False\n",
    "\n",
    "                if eye_close_count < max_frame_count and mouth_open_count < max_frame_count:\n",
    "                    cv2.putText(frame, \"Active :)\", (250, 50), font, 1, (31, 163, 21))\n",
    "                    self.soundOff()\n",
    "                    if drowsy:\n",
    "                        drowsy = False\n",
    "                else:\n",
    "                    cv2.putText(frame, \"Drowsy!\", (250, 50), font, 1, (255, 0, 0))\n",
    "                    self.soundOn()\n",
    "                    if not drowsy:\n",
    "                        drowsy_count += 1\n",
    "                        drowsy = True\n",
    "\n",
    "                for i in le + re + il + ol:  # Plot facial landmarks\n",
    "                    (x, y) = (face_landmarks[i][0], face_landmarks[i][1])\n",
    "                    cv2.circle(frame, (x, y), 1, (255, 255, 255), -1)\n",
    "\n",
    "            else:\n",
    "                self.soundOff()\n",
    "\n",
    "            cv2.imshow(\"Driver Drowsiness Detection System\", frame) # Display frame\n",
    "\n",
    "            key = cv2.waitKey(1)    # Press Esc to exit\n",
    "            if key == 27:\n",
    "                break\n",
    "\n",
    "        self.soundOff()\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "obj = Project()\n",
    "video_path = (input(\"Enter path of video: \") or 0)\n",
    "obj.drowsinessDetectionSystem(video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import dlib\n",
    "import cv2\n",
    "import xlsxwriter\n",
    "from math import hypot\n",
    "\n",
    "\n",
    "class GenDataset:\n",
    "\n",
    "    def generateDataset(self, video_path):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "        n = video_path.split(\"\\\\\")[-1]\n",
    "        n = n.split(\".\")[0]\n",
    "        workbook = xlsxwriter.Workbook(\"Testing Dataset\\\\Annotation\\\\\" + n + \".xlsx\")\n",
    "        worksheet = workbook.add_worksheet()\n",
    "        worksheet.write('A1', 'Frame Number')\n",
    "        worksheet.write('B1', 'Drowsy Status')\n",
    "\n",
    "        frame_count = 0\n",
    "        font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:     # If no frame is detected then stop\n",
    "                break\n",
    "\n",
    "            frame_count += 1\n",
    "            frame = cv2.flip(frame, 1)\n",
    "\n",
    "            key = cv2.waitKey(75) \n",
    "            if key == 27:   # Press Esc to exit\n",
    "                break\n",
    "            elif key == 100:    # Press d to enter drowsy state\n",
    "                worksheet.write('B'+str(frame_count+1), 1)\n",
    "                cv2.putText(frame, \"Drowsy!\", (250, 50), font, 1, (255, 0, 0))\n",
    "            else:\n",
    "                worksheet.write('B'+str(frame_count+1), 0)\n",
    "                cv2.putText(frame, \"Active :)\", (250, 50), font, 1, (31, 163, 21))\n",
    "            worksheet.write('A'+str(frame_count+1), frame_count)\n",
    "\n",
    "            cv2.imshow(\"Generate Dataset\", frame) # Display frame\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        workbook.close()\n",
    "\n",
    "obj = GenDataset()\n",
    "video_path = input(\"Enter path of video: \")\n",
    "obj.generateDataset(video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Dataset from Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import dlib\n",
    "import cv2\n",
    "import xlsxwriter\n",
    "from math import hypot\n",
    "\n",
    "\n",
    "class GenDatasetAlgo:\n",
    "\n",
    "    def aspect_ratio(self, landmark_list, face_landmark):   # Calculate Aspect Ratio\n",
    "        n = len(landmark_list)\n",
    "        left_point = (face_landmark.part(landmark_list[0]).x, face_landmark.part(landmark_list[0]).y)\n",
    "        right_point = (face_landmark.part(landmark_list[n//2]).x, face_landmark.part(landmark_list[n//2]).y)\n",
    "        # Calculate Horizontal Length\n",
    "        hor_length = hypot((left_point[0] - right_point[0]), (left_point[1] - right_point[1]))\n",
    "\n",
    "        top = list()    # Co-ordinates of the upper part    \n",
    "        bottom = list() # Co-ordinates of the lower part \n",
    "\n",
    "        for i in range(1, n//2):\n",
    "            top.append((face_landmark.part(landmark_list[i]).x, face_landmark.part(landmark_list[i]).y))\n",
    "            bottom.append((face_landmark.part(landmark_list[-1*i]).x, face_landmark.part(landmark_list[-1*i]).y))\n",
    "\n",
    "        ver_lengths = list()\n",
    "        for i in range(len(top)):   # Calculate vertical lengths\n",
    "            ver_lengths.append(hypot((top[i][0] - bottom[i][0]), (top[i][1] - bottom[i][1])))\n",
    "\n",
    "        s = len(ver_lengths)\n",
    "        ratio = sum(ver_lengths) / (s * hor_length) # Calculate aspect ratio\n",
    "        return ratio\n",
    "\n",
    "    def generateDatasetAlgo(self, videos_dir):\n",
    "        for f1 in os.listdir(videos_dir):\n",
    "            video = os.fsdecode(f1)\n",
    "            cap = cv2.VideoCapture(videos_dir + \"\\\\\" + video)\n",
    "            detector = dlib.get_frontal_face_detector()\n",
    "            predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "            n = video.split(\".\")[0]\n",
    "            workbook = xlsxwriter.Workbook(\"Testing Dataset\\\\Annotation\\\\\" + n + \".xlsx\")\n",
    "            worksheet = workbook.add_worksheet()\n",
    "            worksheet.write('A1', 'Frame Number')\n",
    "            worksheet.write('B1', 'Drowsy Status')\n",
    "\n",
    "            eye_close_count = 0\n",
    "            mouth_open_count = 0\n",
    "            font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "            frame_count = 0\n",
    "\n",
    "            max_ear = 0\n",
    "            min_ear = 1\n",
    "            per = 35\n",
    "            threshold_ear = 0.25\n",
    "            threshold_mar = 0.35\n",
    "            max_frame_count = 20\n",
    "\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:     # If no frame is detected then stop\n",
    "                    break\n",
    "                if video.split('.')[-1] == \"mp4\":\n",
    "                    frame = cv2.resize(frame, (1600, 900))\n",
    "\n",
    "                frame_count += 1\n",
    "                frame = cv2.flip(frame, 1)\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # Convert the image to gray scale\n",
    "                faces = detector(gray)  # Detect faces and get the co-ordinates of the rectangle where face is detected\n",
    "\n",
    "                if 0 < len(faces):\n",
    "                    face = faces[0]     # Consider only 1st detected face\n",
    "                    face_landmark = predictor(gray, face)   # Get facial landmarks\n",
    "\n",
    "                    left_eye_ratio = self.aspect_ratio(list(range(36, 42)), face_landmark)\n",
    "                    right_eye_ratio = self.aspect_ratio(list(range(42, 48)), face_landmark)\n",
    "                    eye_aspect_ratio = (left_eye_ratio + right_eye_ratio) / 2   # Calculate eye aspect ratio\n",
    "\n",
    "                    inner_lip_ratio = self.aspect_ratio(list(range(60, 68)), face_landmark)\n",
    "                    outter_lip_ratio = self.aspect_ratio(list(range(48, 60)), face_landmark)\n",
    "                    mouth_aspect_ratio = (inner_lip_ratio + outter_lip_ratio) / 2 # Calculate mouth aspect ratio\n",
    "\n",
    "                    max_ear = max(max_ear, eye_aspect_ratio)\n",
    "                    min_ear = min(min_ear, eye_aspect_ratio)\n",
    "                    diff = max_ear - min_ear\n",
    "                    threshold_ear = min_ear + diff * per / 100      # Calculate threshold eye aspect ratio\n",
    "\n",
    "                    if eye_aspect_ratio < threshold_ear:\n",
    "                        eye_close_count += 1\n",
    "                    else:\n",
    "                        eye_close_count = 0\n",
    "\n",
    "                    if mouth_aspect_ratio > threshold_mar:\n",
    "                        mouth_open_count += 1\n",
    "                    else:\n",
    "                        mouth_open_count = 0\n",
    "\n",
    "                    if eye_close_count < max_frame_count and mouth_open_count < max_frame_count:\n",
    "                        worksheet.write('B'+str(frame_count+1), 0)\n",
    "                        cv2.putText(frame, \"Active :)\", (250, 50), font, 1, (31, 163, 21))\n",
    "                    else:\n",
    "                        worksheet.write('B'+str(frame_count+1), 1)\n",
    "                        cv2.putText(frame, \"Drowsy!\", (250, 50), font, 1, (255, 0, 0))\n",
    "\n",
    "                else:\n",
    "                    worksheet.write('B'+str(frame_count+1), 0)\n",
    "                worksheet.write('A'+str(frame_count+1), frame_count)\n",
    "\n",
    "                cv2.imshow(\"Generate Dataset from Algorithm\", frame) # Display frame\n",
    "\n",
    "                key = cv2.waitKey(1)    # Press Esc to exit\n",
    "                if key == 27:\n",
    "                    break\n",
    "\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            workbook.close()\n",
    "\n",
    "obj = GenDatasetAlgo()\n",
    "video_dir = input(\"Enter path of videos directory: \")\n",
    "obj.generateDatasetAlgo(video_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing one video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85198\n",
      "Precision: 0.73707\n",
      "Recall: 0.65896\n",
      "F1 Score: 0.69583\n"
     ]
    }
   ],
   "source": [
    "# import the necessary libraries\n",
    "import dlib\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from math import hypot\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "class Test:\n",
    "\n",
    "    def aspect_ratio(self, landmark_list, face_landmark):   # Calculate Aspect Ratio\n",
    "        n = len(landmark_list)\n",
    "        left_point = (face_landmark.part(landmark_list[0]).x, face_landmark.part(landmark_list[0]).y)\n",
    "        right_point = (face_landmark.part(landmark_list[n//2]).x, face_landmark.part(landmark_list[n//2]).y)\n",
    "        # Calculate Horizontal Length\n",
    "        hor_length = hypot((left_point[0] - right_point[0]), (left_point[1] - right_point[1]))\n",
    "\n",
    "        top = list()    # Co-ordinates of the upper part    \n",
    "        bottom = list() # Co-ordinates of the lower part \n",
    "\n",
    "        for i in range(1, n//2):\n",
    "            top.append((face_landmark.part(landmark_list[i]).x, face_landmark.part(landmark_list[i]).y))\n",
    "            bottom.append((face_landmark.part(landmark_list[-1*i]).x, face_landmark.part(landmark_list[-1*i]).y))\n",
    "\n",
    "        ver_lengths = list()\n",
    "        for i in range(len(top)):   # Calculate vertical lengths\n",
    "            ver_lengths.append(hypot((top[i][0] - bottom[i][0]), (top[i][1] - bottom[i][1])))\n",
    "\n",
    "        s = len(ver_lengths)\n",
    "        ratio = sum(ver_lengths) / (s * hor_length) # Calculate aspect ratio\n",
    "        return ratio\n",
    "\n",
    "    def testing(self, video_path):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        detector = dlib.get_frontal_face_detector()\n",
    "        predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "        eye_close_count = 0\n",
    "        mouth_open_count = 0\n",
    "        font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "        max_ear = 0\n",
    "        min_ear = 1\n",
    "        per = 35\n",
    "        threshold_ear = 0.25\n",
    "        threshold_mar = 0.35\n",
    "        max_frame_count = 20\n",
    "\n",
    "        n = video_path.split(\"\\\\\")[-1]\n",
    "        n = n.split(\".\")[0]\n",
    "        df = pd.read_excel(\"Testing Dataset\\\\Annotation\\\\\" + n + \".xlsx\")\n",
    "        actual = df[\"Drowsy Status\"].to_list()\n",
    "        predicted = list()\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:     # If no frame is detected then stop\n",
    "                break\n",
    "            if video_path.split('.')[-1] == \"mp4\":\n",
    "                frame = cv2.resize(frame, (1600, 900))\n",
    "\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # Convert the image to gray scale\n",
    "            faces = detector(gray)  # Detect faces and get the co-ordinates of the rectangle where face is detected\n",
    "\n",
    "            if 0 < len(faces):\n",
    "                face = faces[0]     # Consider only 1st detected face\n",
    "                face_landmark = predictor(gray, face)   # Get facial landmarks\n",
    "\n",
    "                left_eye_ratio = self.aspect_ratio(list(range(36, 42)), face_landmark)\n",
    "                right_eye_ratio = self.aspect_ratio(list(range(42, 48)), face_landmark)\n",
    "                eye_aspect_ratio = (left_eye_ratio + right_eye_ratio) / 2   # Calculate eye aspect ratio\n",
    "\n",
    "                inner_lip_ratio = self.aspect_ratio(list(range(60, 68)), face_landmark)\n",
    "                outter_lip_ratio = self.aspect_ratio(list(range(48, 60)), face_landmark)\n",
    "                mouth_aspect_ratio = (inner_lip_ratio + outter_lip_ratio) / 2 # Calculate mouth aspect ratio\n",
    "\n",
    "                max_ear = max(max_ear, eye_aspect_ratio)\n",
    "                min_ear = min(min_ear, eye_aspect_ratio)\n",
    "                diff = max_ear - min_ear\n",
    "                threshold_ear = min_ear + diff * per / 100      # Calculate threshold eye aspect ratio\n",
    "\n",
    "                if eye_aspect_ratio < threshold_ear:\n",
    "                    eye_close_count += 1\n",
    "                else:\n",
    "                    eye_close_count = 0\n",
    "\n",
    "                if mouth_aspect_ratio > threshold_mar:\n",
    "                    mouth_open_count += 1\n",
    "                else:\n",
    "                    mouth_open_count = 0\n",
    "\n",
    "                if eye_close_count < max_frame_count and mouth_open_count < max_frame_count:\n",
    "                    cv2.putText(frame, \"Active :)\", (250, 50), font, 1, (31, 163, 21))\n",
    "                    predicted.append(0)\n",
    "                else:\n",
    "                    cv2.putText(frame, \"Drowsy!\", (250, 50), font, 1, (255, 0, 0))\n",
    "                    predicted.append(1)\n",
    "            else:\n",
    "                predicted.append(0)\n",
    "\n",
    "            cv2.imshow(\"Driver Drowsiness Detection System\", frame) # Display frame\n",
    "\n",
    "            key = cv2.waitKey(1)    # Press Esc to exit\n",
    "            if key == 27:\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        if len(actual) != len(predicted):\n",
    "            print(\"Error in\", video_path.split(\"\\\\\")[-1])\n",
    "            return\n",
    "\n",
    "        cm = confusion_matrix(actual, predicted)\n",
    "        plt.figure()\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.show()\n",
    "\n",
    "        # Accuracy Score = (TP + TN) / (TP + FN + TN + FP)\n",
    "        print('Accuracy:', round(accuracy_score(actual, predicted), 5))\n",
    "\n",
    "        # Precision Score = TP / (FP + TP)\n",
    "        print('Precision:', round(precision_score(actual, predicted), 5))\n",
    "\n",
    "        # Recall Score = TP / (FN + TP)    \n",
    "        print('Recall:', round(recall_score(actual, predicted), 5))\n",
    "\n",
    "        # F1 Score = 2 * Precision Score * Recall Score / (Precision Score + Recall Score)\n",
    "        print('F1 Score:', round(f1_score(actual, predicted), 5))\n",
    "\n",
    "obj = Test()\n",
    "video_path = input(\"Enter path of video: \")\n",
    "obj.testing(video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import dlib\n",
    "import cv2\n",
    "import os\n",
    "import xlsxwriter\n",
    "import pandas as pd\n",
    "from math import hypot\n",
    "\n",
    "\n",
    "class Predict:\n",
    "    def aspect_ratio(self, landmark_list, face_landmark):   # Calculate Aspect Ratio\n",
    "        n = len(landmark_list)\n",
    "        left_point = (face_landmark.part(landmark_list[0]).x, face_landmark.part(landmark_list[0]).y)\n",
    "        right_point = (face_landmark.part(landmark_list[n//2]).x, face_landmark.part(landmark_list[n//2]).y)\n",
    "        # Calculate Horizontal Length\n",
    "        hor_length = hypot((left_point[0] - right_point[0]), (left_point[1] - right_point[1]))\n",
    "\n",
    "        top = list()    # Co-ordinates of the upper part    \n",
    "        bottom = list() # Co-ordinates of the lower part \n",
    "\n",
    "        for i in range(1, n//2):\n",
    "            top.append((face_landmark.part(landmark_list[i]).x, face_landmark.part(landmark_list[i]).y))\n",
    "            bottom.append((face_landmark.part(landmark_list[-1*i]).x, face_landmark.part(landmark_list[-1*i]).y))\n",
    "\n",
    "        ver_lengths = list()\n",
    "        for i in range(len(top)):   # Calculate vertical lengths\n",
    "            ver_lengths.append(hypot((top[i][0] - bottom[i][0]), (top[i][1] - bottom[i][1])))\n",
    "\n",
    "        s = len(ver_lengths)\n",
    "        ratio = sum(ver_lengths) / (s * hor_length) # Calculate aspect ratio\n",
    "        return ratio\n",
    "\n",
    "    def pred(self, dir1, dir2):\n",
    "\n",
    "        data_present = pd.read_excel(\"Testing Dataset\\\\Results.xlsx\")[\"Video\"].unique()\n",
    "\n",
    "        for (f1, f2) in zip(os.listdir(dir1), os.listdir(dir2)):\n",
    "            file_name = os.fsdecode(f1)\n",
    "            annot_name = os.fsdecode(f2)\n",
    "\n",
    "            if file_name in data_present:\n",
    "                print(\"Data for video\", file_name, \"is already present.\")\n",
    "                continue\n",
    "\n",
    "            if file_name.split('.')[0] == annot_name.split('.')[0]: \n",
    "                video_path = os.path.join(dir1, file_name)\n",
    "                annot_path = os.path.join(dir2, annot_name)\n",
    "\n",
    "                cap = cv2.VideoCapture(video_path)\n",
    "                detector = dlib.get_frontal_face_detector()\n",
    "                predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "                eye_close_count = 0\n",
    "                mouth_open_count = 0\n",
    "                font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "                max_ear = 0\n",
    "                min_ear = 1\n",
    "                per = 35\n",
    "                threshold_ear = 0.25\n",
    "                threshold_mar = 0.35\n",
    "                max_frame_count = 20\n",
    "                frame_count = 0\n",
    "\n",
    "                df = pd.read_excel(annot_path)\n",
    "                actual = df[\"Drowsy Status\"].to_list()\n",
    "                predicted = list()\n",
    "\n",
    "                while True:\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:     # If no frame is detected then stop\n",
    "                        break\n",
    "                    if video_path.split('.')[-1] == \"mp4\":\n",
    "                        frame = cv2.resize(frame, (1600, 900))\n",
    "\n",
    "                    frame_count += 1\n",
    "                    frame = cv2.flip(frame, 1)\n",
    "                    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # Convert the image to gray scale\n",
    "                    faces = detector(gray)  # Detect faces and get the co-ordinates of the rectangle where face is detected\n",
    "\n",
    "                    if 0 < len(faces):\n",
    "                        face = faces[0]     # Consider only 1st detected face\n",
    "                        face_landmark = predictor(gray, face)   # Get facial landmarks\n",
    "\n",
    "                        left_eye_ratio = self.aspect_ratio(list(range(36, 42)), face_landmark)\n",
    "                        right_eye_ratio = self.aspect_ratio(list(range(42, 48)), face_landmark)\n",
    "                        eye_aspect_ratio = (left_eye_ratio + right_eye_ratio) / 2   # Calculate eye aspect ratio\n",
    "\n",
    "                        inner_lip_ratio = self.aspect_ratio(list(range(60, 68)), face_landmark)\n",
    "                        outter_lip_ratio = self.aspect_ratio(list(range(48, 60)), face_landmark)\n",
    "                        mouth_aspect_ratio = (inner_lip_ratio + outter_lip_ratio) / 2 # Calculate mouth aspect ratio\n",
    "\n",
    "                        max_ear = max(max_ear, eye_aspect_ratio)\n",
    "                        min_ear = min(min_ear, eye_aspect_ratio)\n",
    "                        diff = max_ear - min_ear\n",
    "                        threshold_ear = min_ear + diff * per / 100      # Calculate threshold eye aspect ratio\n",
    "\n",
    "                        if eye_aspect_ratio < threshold_ear:\n",
    "                            eye_close_count += 1\n",
    "                        else:\n",
    "                            eye_close_count = 0\n",
    "\n",
    "                        if mouth_aspect_ratio > threshold_mar:\n",
    "                            mouth_open_count += 1\n",
    "                        else:\n",
    "                            mouth_open_count = 0\n",
    "\n",
    "                        if eye_close_count < max_frame_count and mouth_open_count < max_frame_count:\n",
    "                            cv2.putText(frame, \"Active :)\", (250, 50), font, 1, (31, 163, 21))\n",
    "                            predicted.append(0)\n",
    "                        else:\n",
    "                            cv2.putText(frame, \"Drowsy!\", (250, 50), font, 1, (255, 0, 0))\n",
    "                            predicted.append(1)\n",
    "                    else:\n",
    "                        predicted.append(0)\n",
    "\n",
    "                    cv2.imshow(\"Driver Drowsiness Detection System\", frame) # Display frame\n",
    "\n",
    "                    key = cv2.waitKey(1)    # Press Esc to exit\n",
    "                    if key == 27:\n",
    "                        break\n",
    "\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "\n",
    "                if len(actual) == len(predicted):\n",
    "                    df2 = pd.DataFrame({\"Video\": file_name, \"Frame Number\": list(range(1, frame_count+1)), \"Actual\": actual, \"Predicted\": predicted})\n",
    "                    with pd.ExcelWriter(\"Testing Dataset\\\\Results.xlsx\", mode=\"r+\", engine=\"openpyxl\", if_sheet_exists=\"overlay\") as writer:\n",
    "                        df2.to_excel(writer, sheet_name=\"Sheet1\", header=None, startrow=writer.sheets[\"Sheet1\"].max_row, startcol=0, index=False)\n",
    "                else:\n",
    "                    print(\"Error in video\", file_name)\n",
    "            else:\n",
    "                print(\"Error in video\", file_name)\n",
    "\n",
    "obj = Predict()\n",
    "obj.pred(\"Testing Dataset\\\\Videos\\\\\", \"Testing Dataset\\\\Annotation\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEWCAYAAAB2X2wCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAAsTAAALEwEAmpwYAAAdCklEQVR4nO3debxVdb3/8debgyiiMqopaNhVM/SXQ2UOaSam4hCaA6gVEl1MscHqKg5XrlM3S0sr9EaKDCqTQ6KpiIgpqQwiDmAKYSYgAjKUI5xzPr8/9jq4gTNs4Oyz9/nyfvZYD/b6rrXX+uzj6bO/57O+67sUEZiZWfPXotQBmJlZ43BCNzNLhBO6mVkinNDNzBLhhG5mlggndDOzRDih22aT1FrSg5JWSRq3Gcc5R9JjjRlbKUh6RFKfUsdhWx4n9C2IpLMlzZD0nqS3s8TzlUY49OnAzkDHiDhjUw8SEXdFxLGNEM86JB0lKSTdv177/ln7kwUe538k3dnQfhHRIyKGb2K4ZpvMCX0LIeknwE3Az8kl392BW4CejXD4TwOvR0RlIxyrWJYCh0rqmNfWB3i9sU6gHP9/ykrGv3xbAEltgauBARFxX0S8HxFrIuLBiPivbJ+tJd0kaVG23CRp62zbUZIWSPqppCVZ775vtu0q4EqgV9bz77d+T1ZS16wn3DJbP1fSfEn/lvSGpHPy2qfkve8wSdOzUs50SYflbXtS0jWS/pod5zFJner5MawG/gT0zt5fAfQC7lrvZ3WzpLck/UvS85KOyNqPBy7L+5wv5sVxnaS/Ah8An8navpdtv1XSvXnHv17SJEkq9L+fWaGc0LcMhwLbAPfXs8/lwCHAAcD+wMHAFXnbPwW0BToD/YDBktpHxCByvf4xEbFdRNxeXyCS2gC/BXpExPbAYcCsWvbrAPw527cj8Gvgz+v1sM8G+gI7Aa2An9V3bmAE8J3s9XHAK8Ci9faZTu5n0AG4GxgnaZuIeHS9z7l/3nu+DfQHtgfeXO94PwX+X/ZldQS5n12f8JwbVgRO6FuGjsCyBkoi5wBXR8SSiFgKXEUuUdVYk21fExEPA+8Bn93EeKqB/SS1joi3I2J2LfucCMyNiJERURkRo4C/ASfn7XNHRLweER8CY8kl4jpFxDNAB0mfJZfYR9Syz50R8W52zhuBrWn4cw6LiNnZe9asd7wPyP0cfw3cCfwgIhY0cDyzTeKEvmV4F+hUU/Kow66s27t8M2tbe4z1vhA+ALbb2EAi4n1ypY7vA29L+rOkfQqIpyamznnrizchnpHAhcDXqOUvFkk/k/RqVuZZSe6vkvpKOQBv1bcxIqYC8wGR++IxKwon9C3Ds8DHwCn17LOI3MXNGruzYTmiUO8D2+atfyp/Y0RMiIivA7uQ63X/sYB4amJauIkx1RgJXAA8nPWe18pKIhcDZwLtI6IdsIpcIgaoq0xSb/lE0gByPf1F2fHNisIJfQsQEavIXbgcLOkUSdtK2kpSD0m/zHYbBVwhacfs4uKV5EoEm2IWcKSk3bMLspfWbJC0s6SeWS39Y3Klm+pajvEwsHc21LKlpF5AN+ChTYwJgIh4A/gquWsG69seqCQ3IqalpCuBHfK2vwN03ZiRLJL2Bq4FvkWu9HKxpAM2LXqz+jmhbyGyevBPyF3oXEquTHAhuZEfkEs6M4CXgJeBmVnbppxrIjAmO9bzrJuEW2RxLAKWk0uu59dyjHeBk8hdVHyXXM/2pIhYtikxrXfsKRFR218fE4BHyQ1lfBP4iHXLKTU3Tb0raWZD58lKXHcC10fEixExl9xImZE1I4jMGpN8sd3MLA3uoZuZJcIJ3cwsEU7oZmaJcEI3M0tEfTealNSaZfN9tdY20HrXI0odgpWhytULN3tunI3JOVt1+kxZzsVTtgndzKxJVVeVOoLN5oRuZgYQtd3f1rw4oZuZAVQ7oZuZJSHcQzczS0RVOT9wqzBO6GZm4IuiZmbJcMnFzCwRvihqZpYGXxQ1M0uFe+hmZomoWtPwPmXOCd3MDHxR1MwsGS65mJklwj10M7NEuIduZpaGqPZFUTOzNLiHbmaWCNfQzcwS4cm5zMwS4R66mVkiXEM3M0uEH3BhZpYI99DNzNIQ4YuiZmZpcA/dzCwRHuViZpYI99DNzBLhUS5mZolwycXMLBEuuZiZJcIJ3cwsES65mJklwhdFzcwS4ZKLmVkiXHIxM0uEe+hmZolwQjczS0REqSPYbE7oZmYAlc1/lEuLUgdgZlYWorrwpQCSKiS9IOmhbH0PSVMlzZM0RlKrrH3rbH1etr1r3jEuzdpfk3RcQ+d0Qjczg1wNvdClMD8CXs1bvx74TUTsCawA+mXt/YAVWftvsv2Q1A3oDewLHA/cIqmivhM6oZuZQa6GXujSAEldgBOB27J1AUcD92S7DAdOyV73zNbJtnfP9u8JjI6IjyPiDWAecHB953VCNzODjeqhS+ovaUbe0n+9o90EXAzUdOc7AisjoqZQvwDonL3uDLwFkG1fle2/tr2W99TKF0XNzGCjhi1GxBBgSG3bJJ0ELImI5yUd1SixFcgJ3cwMiKpGe0j04cA3JJ0AbAPsANwMtJPUMuuFdwEWZvsvBHYDFkhqCbQF3s1rr5H/nlq55GJmBo12UTQiLo2ILhHRldxFzSci4hxgMnB6tlsf4IHs9fhsnWz7ExERWXvvbBTMHsBewLT6zu0eupkZNMVcLpcAoyVdC7wA3J613w6MlDQPWE7uS4CImC1pLDAHqAQGRES9f0Y4oZuZAVQ3/p2iEfEk8GT2ej61jFKJiI+AM+p4/3XAdYWezwndzAw8l4uZWTIa76JoyfiiaAlVVVVx+rkDuOC/BgEw9flZnNH3Qk751ve57JobqKzM/YJNm/kShxx7Gqf1GcBpfQZw69C71h5jynMzOKn39+hx5ne5beTYknwOK44/DrmRRQteZNYLk9a2Xf+/V/DKy39h5vMTuWfcbbRtuwMAx3Q/gqnPPcILMx9n6nOP8LWjDi9V2M1X498p2uSc0EvoznEP8JmuuwNQXV3NZdfeyK+uGsif7vw/dv3UTjzwyONr9z1o//24d/hg7h0+mPO/ew6Q+0K49sbB3HrjNYy/6w88/PiT/P2NN0vyWazxjRgxlhNPOmedtscnPcX+BxzNQV/4OnPnzmfgJRcCsOzd5Zxy6rkceNAxfLffjxl2x82lCLl5q47ClzLlhF4ii5cs5alnpnHaybn5dlau+hdbtWxJ1927AHDolw7i8Sen1HuMl199nd277MpunXdhq622okf3r/LE088VPXZrGk9PmcryFSvXaZv4+FNUZaWB56bOpHPnXQCYNWs2b7/9DgCzZ79G69bb0KpVqyaNt9lr5Mm5SqFoCV3SPpIukfTbbLlE0ueKdb7m5vqb/8BPLuiHlPtP0L5dW6qqqnnl1dcBeOzJKSxesmzt/i++8irf7HMB3//pfzNvfq4XvmTpMj61045r99l5p04sWfpuE34KK6W+5/bm0QmTN2j/5jdP5IUXXmH16tUliKoZcw+9dpIuAUYDIjcQflr2epSkgfW8b+38CLeNGFWM0MrCk3+dSof27dh3n73WtkniV1cP5Je/HULv7/2INtu2pkWL3H+ebp/9DybeO5z7ht/C2aedzA8vvbpUoVuZuHTgD6msrOTuu+9bp71bt7353+su4/wBl5QosuYrqqsLXspVsUa59AP2jYg1+Y2Sfg3MBn5R25vy50dYs2x++X4NbqYXXprDk1Oe4+lnp/Px6jW8//4HXHLVL7l+0MWMuPUGAP469XnefCt3l+92bdqsfe+Rhx3MtTcOZsXKVey0YycWL1m6dts7S5ax044dm/bDWJP7zrfP5MQTjuHrx525Tnvnzrtwz7jb6fvdHzF/vq+lbLQERrkUK6FXA7sC6/9W7cIns49tsS46vy8Xnd8XyI1gGTbqXq4fdDHvrlhJx/btWL16NUPvGkf/Pr2B3AWvjh3aI4mX57xGdQTt2u7A9tttxz8XLGLBosXsvGNHHpn0F345yD2zlB137FH87Gfnc3T30/jww4/WtrdtuwPjHxjBZZf/nGeenVHCCJuxMi6lFKpYCf3HwCRJc/lk+sfdgT2BC4t0zmbvjrvu4S/PTCOqq+l16ol8+QsHAPDY5CmMuf/PVLSsYJtWrfjVVQORRMuWFVx20fmc95MrqKqq4tSTjmXPz3y6tB/CGs2dIwfz1SMPpVOnDvxj/gyuuvoGLrn4QrbeemsefWQ0AFOnzmTAhQMZcEFf9vyPrlxx+UVccflFAPQ44SyW+ppK4cq4lFIoRZEejKrc1b6D+WT+3oXA9IbmIqiRcsnFNl3rXY8odQhWhipXL9TmHuP9K3sXnHPaXD16s89XDEW7UzQiqgGPoTOz5qGMhyMWyrf+m5mBa+hmZqmISo9yMTNLg3voZmaJcA3dzCwR7qGbmaUhnNDNzBLhi6JmZolwD93MLBFO6GZmaSjWNChNyQndzAzcQzczS4YTuplZGqLSNxaZmaWh+edzJ3QzM/CNRWZm6XBCNzNLhEsuZmZpcMnFzCwRUemEbmaWBpdczMzSkMDzLZzQzcwA99DNzFLhHrqZWSKistQRbL4WpQ7AzKwcRHXhS30kbSNpmqQXJc2WdFXWvoekqZLmSRojqVXWvnW2Pi/b3jXvWJdm7a9JOq6hz+CEbmZG4yV04GPg6IjYHzgAOF7SIcD1wG8iYk9gBdAv278fsCJr/022H5K6Ab2BfYHjgVskVdR3Yid0MzOAUOFLfYfJeS9b3SpbAjgauCdrHw6ckr3uma2Tbe8uSVn76Ij4OCLeAOYBB9d3bid0MzM2rocuqb+kGXlL//xjSaqQNAtYAkwE/g6sjFhbqV8AdM5edwbeAsi2rwI65rfX8p5a+aKomRkQ1fX3vNfZN2IIMKSe7VXAAZLaAfcD+2xufIVwQjczA6qrCk/ohYqIlZImA4cC7SS1zHrhXYCF2W4Lgd2ABZJaAm2Bd/Paa+S/p1YuuZiZ0aijXHbMeuZIag18HXgVmAycnu3WB3ggez0+Wyfb/kTknlg9HuidjYLZA9gLmFbfud1DNzNj40ouDdgFGJ6NSGkBjI2IhyTNAUZLuhZ4Abg92/92YKSkecByciNbiIjZksYCc4BKYEBWyqmTcl8E5WfNsvnlGZiVVOtdjyh1CFaGKlcv3Oxs/M8vdi845+w+Y1Lj12cagXvoZmY0ag+9ZJzQzcwozkXRpuaEbmZG4j10Sb8jd3dTrSLih0WJyMysBKKBO0Cbg/p66DOaLAozsxJLevrciBhe1zYzs9RUJ95DB3KD5IFLgG7ANjXtEXF0EeMyM2tSKZRcCrlT9C5ydzntAVwF/AOYXsSYzMyaXHWVCl7KVSEJvWNE3A6siYi/RMR3yU0DaWaWjKhWwUu5KmTY4prs37clnQgsAjoULyQzs6a3RdTQgWsltQV+CvwO2AG4qKhRmZk1sRRq6A0m9Ih4KHu5CvhaccMxMyuNMp3WaqMUMsrlDmq5wSirpZuZJWFLKbk8lPd6G+BUcnV0M7NkVJfxxc5CFVJyuTd/XdIoYErRIjIzK4EtpYe+vr2AnRo7kPW16XxksU9hzdAebT9V6hAsUVvERVFJ/2bdGvpicneOmpklY4vooUfE9k0RiJlZKSUwyKXhO0UlTSqkzcysOauqblHwUq7qmw99G2BboJOk9kDN3yM7AJ2bIDYzsyaTwOy59ZZczgN+DOwKPM8nCf1fwO+LG5aZWdMKEq6hR8TNwM2SfhARv2vCmMzMmlx1AkX0QopB1ZLa1axIai/pguKFZGbW9KpRwUu5KiSh/2dErKxZiYgVwH8WLSIzsxIIVPBSrgq5sahCkiJyU9dIqgBaFTcsM7OmVVXGibpQhST0R4Exkv6QrZ8HPFK8kMzMml7qo1xqXAL0B76frb8E+P5rM0tKCgm9wRp6RFQDU8k9S/Rgco+fe7W4YZmZNa2ka+iS9gbOypZlwBiAiPBDLswsOQnMnltvyeVvwNPASRExD0CSHz1nZkkq5+GIhaqv5PJN4G1gsqQ/SuoOCXxiM7NaVG3EUq7qTOgR8aeI6A3sA0wmNw3ATpJulXRsE8VnZtYkqqWCl3JVyEXR9yPi7og4GegCvIDnQzezxMRGLOVqo+aBjIgVETEkIroXKyAzs1Ko3oilXG3KI+jMzJKT+igXM7MtRgq3/pfvozfMzJpQtQpf6iNpN0mTJc2RNFvSj7L2DpImSpqb/ds+a5ek30qaJ+klSQflHatPtv9cSX0a+gxO6GZmNGoNvRL4aUR0Aw4BBkjqBgwEJkXEXsCkbB2gB7BXtvQHboXcFwAwCPgyubv0B9V8CdTFCd3MjMYb5RIRb0fEzOz1v8lNldIZ6AkMz3YbDpySve4JjIic54B2knYBjgMmRsTybNryicDx9Z3bCd3MjI0ruUjqL2lG3tK/tmNK6gocSG4+rJ0j4u1s02Jg5+x1Z+CtvLctyNrqaq+TL4qambFxwxEjYggwpL59JG0H3Av8OCL+pbwbkiIiJDX6kHb30M3MgCoVvjRE0lbkkvldEXFf1vxOVkoh+3dJ1r4Q2C3v7V2ytrra6+SEbmZG410UVa4rfjvwakT8Om/TeKBmpEof4IG89u9ko10OAVZlpZkJwLHZc5zbA8dmbXVyycXMjEa9A/Rw4NvAy5JmZW2XAb8AxkrqB7wJnJltexg4AZgHfAD0BYiI5ZKuAaZn+10dEcvrO7ETupkZjTdHS0RMoe6ZaTeYNiV7XvOAOo41FBha6Lmd0M3M8K3/ZmbJKOdJtwrlhG5mRnk/uKJQTuhmZrjkYmaWDJdczMwSUc5PIiqUE7qZGVCdQEp3QjczwxdFzcyS4Rq6mVkiPMrFzCwRrqGbmSWi+adzJ3QzM8A1dDOzZFQl0Ed3Qjczwz10M7Nk+KKomVkimn86d0I3MwNccjEzS4YvipqZJSKFGnqLUgdgMOQPN7DgrVm8MPPxtW133XkL06dNYPq0Cbz+2rNMnzYBgLN6n7q2ffq0CXz04T/Z//PdShW6FdHk5x/kob+MYfzku7lv4kgAPrff3ox7ZNjats8fuC8An9mzK2MfvoPZC56l3wXfLmXYzVZsxFKu3EMvAyNGjuOWW4dxx9Cb1rad860L1r6+/vr/5l+r/g3AqNH3M2r0/QDst+8+jLvnNl58aU6TxmtN59unnseK5SvXrl985Y/43Q1DeGrSM3z1mMO5eNAP+dYp57Fy5SquuexXHHPCUSWLtblzD90axZQpU1mxYmWd208/7WTGjH1gg/ZevXoybuz4IkZm5SYIttu+DQDbb78dSxYvA2D5shW8PGsOlWsqSxles1a9EUu5cg+9zH3lK19myZKlzJv3xgbbTj/jZE4/rV8JorKmEBHcMW4wEcHo4fcyZuT9XHf5DQwdO5iB//Nj1KIFvU7oW+owkxEJ9NCbPKFL6hsRd9SxrT/QH6Cioh0tKto0aWzlqFevnrX2zr/0pQP58IOPmD3ntRJEZU3hrJP68c7ipXTo1J5h425h/rx/cPzJx/Dz/76RCQ89QY+eX+fnN13Juadf0PDBrEEpjHIpRcnlqro2RMSQiPhiRHzRyRwqKio4pWcPxo17cINtZ575DcaM+VPTB2VN5p3FS4FcOWXiw5P5/IH7cWqvk5jw0BMAPPLARPY/aN9ShpiUFEouRUnokl6qY3kZ2LkY50xR9+5H8Nprf2fhwrfXaZfE6aedzNhxrp+nqvW229CmzbZrX3/lqEN4/W/zWLJ4KQcf9gUADj3iS/xj/lulDDMp1REFL+WqWCWXnYHjgBXrtQt4pkjnbLZGjvg9Rx55KJ06dWD+36dz9TU3MmzYaM484xuMGfunDfY/4ohDWLBgEW+88c+mD9aaRKcdOzJ42A0AtGxZwYP3PcrTTzzL5e9fyxXX/YyKigpWf7yaK35ybW7/nTpy/8SRbLd9G6qrg3PPO4seh5/Be++9X8qP0ayUb5ounKII3zaSbgfuiIgptWy7OyLObugYrbbuksLP1xrZp3fwH3i2oblLn9/sB8id/elTC845d795f1k+sK4oPfSIqHPoRSHJ3MysqXmUi5lZIiqd0M3M0uAeuplZIsp5OGKhnNDNzMjdmdvcOaGbmZHG5FxO6GZm+NZ/M7NkVBMFLw2RNFTSEkmv5LV1kDRR0tzs3/ZZuyT9VtK87I76g/Le0yfbf66kPg2d1wndzIxcDb3QpQDDgOPXaxsITIqIvYBJ2TpAD2CvbOkP3Aq5LwBgEPBl4GBgUM2XQF2c0M3MaNzJuSLiKWD5es09geHZ6+HAKXntIyLnOaCdpF3ITZ8yMSKWR8QKYCIbfkmswwndzIzcOPRC/yepv6QZeUv/Ak6xc0TUzLS3mE8mKuwM5M+ytiBrq6u9Tr4oambGxo1yiYghwJBNPVdEhKRGvwrrHrqZGVAV1QUvm+idrJRC9u+SrH0hsFvefl2ytrra6+SEbmbGxpVcNtF4oGakSh/ggbz272SjXQ4BVmWlmQnAsZLaZxdDj83a6uSSi5kZNOqDKySNAo4COklaQG60yi+AsZL6AW8CZ2a7PwycAMwDPgD6AkTEcknXANOz/a6OiPUvtK7DCd3MjMZ9wEVEnFXHpu617BvAgDqOMxQYWuh5ndDNzPCt/2ZmyXBCNzNLxGaMXikbTuhmZvgBF2ZmyfB86GZmiXAN3cwsEe6hm5kloiqBp4o6oZuZ0bh3ipaKE7qZGR7lYmaWDPfQzcwS4R66mVki3EM3M0uEb/03M0uESy5mZokI99DNzNLgW//NzBLhW//NzBLhHrqZWSKqql1DNzNLgke5mJklwjV0M7NEuIZuZpYI99DNzBLhi6JmZolwycXMLBEuuZiZJcLT55qZJcLj0M3MEuEeuplZIqo9fa6ZWRp8UdTMLBFO6GZmiWj+6RyUwrdS6iT1j4ghpY7Dyot/L2x9LUodgBWkf6kDsLLk3wtbhxO6mVkinNDNzBLhhN48uE5qtfHvha3DF0XNzBLhHrqZWSKc0M3MEuGEXuYkHS/pNUnzJA0sdTxWepKGSloi6ZVSx2LlxQm9jEmqAAYDPYBuwFmSupU2KisDw4DjSx2ElR8n9PJ2MDAvIuZHxGpgNNCzxDFZiUXEU8DyUsdh5ccJvbx1Bt7KW1+QtZmZbcAJ3cwsEU7o5W0hsFveepeszcxsA07o5W06sJekPSS1AnoD40sck5mVKSf0MhYRlcCFwATgVWBsRMwubVRWapJGAc8Cn5W0QFK/Usdk5cG3/puZJcI9dDOzRDihm5klwgndzCwRTuhmZolwQjczS4QTuhWFpCpJsyS9ImmcpG0341jDJJ2evb6tvgnKJB0l6bBNOMc/JHXa1BjNyoETuhXLhxFxQETsB6wGvp+/UVLLTTloRHwvIubUs8tRwEYndLMUOKFbU3ga2DPrPT8taTwwR1KFpF9Jmi7pJUnnASjn99k88I8DO9UcSNKTkr6YvT5e0kxJL0qaJKkruS+Oi7K/Do6QtKOke7NzTJd0ePbejpIekzRb0m2AmvhnYtboNqmXZFaorCfeA3g0azoI2C8i3pDUH1gVEV+StDXwV0mPAQcCnyU3B/zOwBxg6HrH3RH4I3BkdqwOEbFc0v8B70XEDdl+dwO/iYgpknYnd9ft54BBwJSIuFrSiYDvtrRmzwndiqW1pFnZ66eB28mVQqZFxBtZ+7HA52vq40BbYC/gSGBURFQBiyQ9UcvxDwGeqjlWRNQ1P/gxQDdpbQd8B0nbZef4ZvbeP0tasWkf06x8OKFbsXwYEQfkN2RJ9f38JuAHETFhvf1OaMQ4WgCHRMRHtcRilhTX0K2UJgDnS9oKQNLektoATwG9shr7LsDXannvc8CRkvbI3tsha/83sH3efo8BP6hZkXRA9vIp4OysrQfQvrE+lFmpOKFbKd1Grj4+M3vg8R/I/dV4PzA32zaC3MyC64iIpUB/4D5JLwJjsk0PAqfWXBQFfgh8MbvoOodPRttcRe4LYTa50ss/i/QZzZqMZ1s0M0uEe+hmZolwQjczS4QTuplZIpzQzcwS4YRuZpYIJ3Qzs0Q4oZuZJeL/A258DFSAA/hIAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94871\n",
      "Precision: 0.82646\n",
      "Recall: 0.76649\n",
      "F1 Score: 0.79535\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "df = pd.read_excel(\"Testing Dataset\\\\Results.xlsx\")\n",
    "actual = df[\"Actual\"].to_list()\n",
    "predicted = df[\"Predicted\"].to_list()\n",
    "\n",
    "if len(actual) != len(predicted):\n",
    "    print(\"Error in data\")\n",
    "    exit(0)\n",
    "\n",
    "cm = confusion_matrix(actual, predicted)\n",
    "plt.figure()\n",
    "plt.title(\"Confusion Matrix\")\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# Accuracy Score = (TP + TN) / (TP + FN + TN + FP)\n",
    "print('Accuracy:', round(accuracy_score(actual, predicted), 5))\n",
    "\n",
    "# Precision Score = TP / (FP + TP)\n",
    "print('Precision:', round(precision_score(actual, predicted), 5))\n",
    "\n",
    "# Recall Score = TP / (FN + TP)    \n",
    "print('Recall:', round(recall_score(actual, predicted), 5))\n",
    "\n",
    "# F1 Score = 2 * Precision Score * Recall Score / (Precision Score + Recall Score)\n",
    "print('F1 Score:', round(f1_score(actual, predicted), 5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete data of a video from Results.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "video = input(\"Enter name of video (with extension): \")\n",
    "df = pd.read_excel(\"Testing Dataset\\\\Results.xlsx\")\n",
    "df = df[df[\"Video\"] != video]\n",
    "\n",
    "df.to_excel(\"Testing Dataset\\\\Results.xlsx\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
