{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver Drowsiness Detection System"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MediaPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import time\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import multiprocessing\n",
    "from math import hypot\n",
    "from playsound import playsound\n",
    "\n",
    "\n",
    "class Project:\n",
    "    def __init__(self):     # Constructor\n",
    "        self.p = multiprocessing.Process()\n",
    "\n",
    "    def soundOn(self):      # Play Sound\n",
    "        if not self.p.is_alive():\n",
    "            self.p = multiprocessing.Process(target=playsound, args=(\"alarm.mp3\",))\n",
    "            self.p.start()\n",
    "\n",
    "    def soundOff(self):     # Stop Sound\n",
    "        if self.p.is_alive():\n",
    "            self.p.terminate()\n",
    "\n",
    "    def aspect_ratio(self, landmark_list, face_landmarks):   # Calculate Aspect Ratio\n",
    "        n = len(landmark_list)\n",
    "\n",
    "        # Calculate horizontal length\n",
    "        left_point = face_landmarks[landmark_list[0]] # (x, y)\n",
    "        right_point = face_landmarks[landmark_list[n//2]]\n",
    "        hor_length = hypot((left_point[0] - right_point[0]), (left_point[1] - right_point[1]))\n",
    "\n",
    "        top = list()    # Co-ordinates of the upper part    \n",
    "        bottom = list() # Co-ordinates of the lower part\n",
    "\n",
    "        for i in range(1, n//2):\n",
    "            top.append(face_landmarks[landmark_list[i]])\n",
    "            bottom.append(face_landmarks[landmark_list[-1*i]])\n",
    "\n",
    "        ver_lengths = list()\n",
    "        for i in range(len(top)):   # Calculate vertical lengths\n",
    "            d = hypot((top[i][0] - bottom[i][0]), (top[i][1] - bottom[i][1]))\n",
    "            ver_lengths.append(d)\n",
    "\n",
    "        s = len(ver_lengths)\n",
    "        ratio = sum(ver_lengths) / (s * hor_length) # Calculate aspect ratio\n",
    "        return ratio\n",
    "\n",
    "    def landmarkCoordinates(self, facelandmarks, image):\n",
    "        coord = list()\n",
    "        ih, iw, ic = image.shape # image height, image width, image channels\n",
    "        for lm in facelandmarks:\n",
    "            x, y = int(lm.x*iw), int(lm.y*ih)\n",
    "            coord.append((x, y))\n",
    "        return coord\n",
    "\n",
    "    def drowsinessDetectionSystem(self, video_path = 0):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        pTime = 0\n",
    "\n",
    "        mpFaceMesh = mp.solutions.face_mesh\n",
    "        faceMesh = mpFaceMesh.FaceMesh()\n",
    "        \n",
    "        eye_close_count = 0\n",
    "        mouth_open_count = 0\n",
    "        font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "        yawn_count = 0\n",
    "        yawning = False\n",
    "        drowsy_count = 0 \n",
    "        drowsy = False\n",
    "\n",
    "        max_ear = 0\n",
    "        min_ear = 1\n",
    "        per = 40\n",
    "        threshold_ear = 0.25\n",
    "        threshold_mar = 0.35\n",
    "        max_frame_count = 20\n",
    "\n",
    "        le = [33, 246, 161, 160, 159, 158, 157, 173,\n",
    "            133, 155, 154, 153, 145, 144, 163, 7]\n",
    "        re = [362, 398, 384, 385, 386, 387, 388, 466,\n",
    "            263, 249, 390, 373, 374, 380, 381, 382]\n",
    "\n",
    "        il = [78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "            308, 324, 318, 402, 317, 14, 87, 178, 88, 95]\n",
    "        ol = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n",
    "            291, 375, 321, 405, 314, 17, 84, 181, 91, 146]\n",
    "        \n",
    "        while True:\n",
    "            success, frame = cap.read()\n",
    "            if not success:     # If no frame is detected then stop\n",
    "                break\n",
    "\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            results = faceMesh.process(frame)  # Detect faces\n",
    "\n",
    "            cTime = time.time()\n",
    "            fps = 1/(cTime - pTime)\n",
    "            pTime = cTime\n",
    "            cv2.putText(frame, f\"FPS: {int(fps)}\", (10, 15), font, 0.5, (0,0,0))\n",
    "\n",
    "            if results.multi_face_landmarks:\n",
    "                face = results.multi_face_landmarks[0]     # Consider only 1st detected face\n",
    "                face_landmarks = self.landmarkCoordinates(face.landmark, frame)   # Get facial landmarks\n",
    "\n",
    "                left_eye_ratio = self.aspect_ratio(le, face_landmarks) # 7vertical 1horizontal\n",
    "                right_eye_ratio = self.aspect_ratio(re, face_landmarks) # 7v 1h\n",
    "                eye_aspect_ratio = (left_eye_ratio + right_eye_ratio) / 2   # Calculate eye aspect ratio\n",
    "                cv2.putText(frame, \"Cur EAR: \"+str(round(eye_aspect_ratio, 5)), (10, 30), font, 0.5, (0, 0, 0))\n",
    "                cv2.putText(frame, \"Thresh EAR: \"+str(round(threshold_ear, 5)), (10, 45), font, 0.5, (0, 0, 0))\n",
    "\n",
    "                cv2.putText(frame, \"Drowsy Count: \"+str(drowsy_count), (250, 15), font, 0.5, (0, 0, 0))\n",
    "\n",
    "                inner_lip_ratio = self.aspect_ratio(il, face_landmarks) # 9v  1h\n",
    "                outter_lip_ratio = self.aspect_ratio(ol, face_landmarks) # 9v 1h\n",
    "                mouth_aspect_ratio = (inner_lip_ratio + outter_lip_ratio) / 2 # Calculate mouth aspect ratio\n",
    "                cv2.putText(frame, \"Cur MAR: \"+str(round(mouth_aspect_ratio, 5)), (475, 15), font, 0.5, (0, 0, 0))\n",
    "                cv2.putText(frame, \"Thresh MAR: \"+str(round(threshold_mar, 5)), (475, 30), font, 0.5, (0, 0, 0))\n",
    "                cv2.putText(frame, \"Yawn Count: \"+str(yawn_count), (475, 45), font, 0.5, (0, 0, 0))\n",
    "\n",
    "                max_ear = max(max_ear, eye_aspect_ratio)\n",
    "                min_ear = min(min_ear, eye_aspect_ratio)\n",
    "                diff = max_ear - min_ear\n",
    "                threshold_ear = min_ear + diff * per / 100      # Calculate threshold eye aspect ratio\n",
    "\n",
    "                if eye_aspect_ratio < threshold_ear:\n",
    "                    eye_close_count += 1\n",
    "                else:\n",
    "                    eye_close_count = 0\n",
    "\n",
    "                if mouth_aspect_ratio > threshold_mar:\n",
    "                    mouth_open_count += 1\n",
    "                else:\n",
    "                    mouth_open_count = 0\n",
    "\n",
    "                if eye_close_count >= max_frame_count:\n",
    "                    cv2.putText(frame, \"Eyes Closed\", (10, 70), font, 0.75, (0, 0, 255))\n",
    "                if mouth_open_count >= max_frame_count:\n",
    "                    cv2.putText(frame, \"Yawning\", (475, 70), font, 0.75, (0, 0, 255))\n",
    "                    if not yawning:\n",
    "                        yawn_count += 1\n",
    "                        yawning = True\n",
    "                else:\n",
    "                    if yawning:\n",
    "                        yawning = False\n",
    "\n",
    "                # Get co-ordinates of rectangle in which face is detected\n",
    "                x1, y1 = face_landmarks[234][0], face_landmarks[10][1]\n",
    "                x2, y2 = face_landmarks[454][0], face_landmarks[152][1]\n",
    "\n",
    "                if eye_close_count < max_frame_count and mouth_open_count < max_frame_count:\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (31, 163, 21), 2)\n",
    "                    cv2.putText(frame, \"Active :)\", (250, 50), font, 1, (31, 163, 21))\n",
    "                    self.soundOff()\n",
    "                    if drowsy:\n",
    "                        drowsy = False\n",
    "                else:\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                    cv2.putText(frame, \"Drowsy!\", (250, 50), font, 1, (255, 0, 0))\n",
    "                    self.soundOn()\n",
    "                    if not drowsy:\n",
    "                        drowsy_count += 1\n",
    "                        drowsy = True\n",
    "\n",
    "                for i in le + re + il + ol:  # Plot facial landmarks\n",
    "                    (x, y) = (face_landmarks[i][0], face_landmarks[i][1])\n",
    "                    cv2.circle(frame, (x, y), 1, (255, 255, 255), -1)\n",
    "\n",
    "            else:\n",
    "                self.soundOff()\n",
    "\n",
    "            cv2.imshow(\"Driver Drowsiness Detection System\", frame) # Display frame\n",
    "\n",
    "            key = cv2.waitKey(20)    # Press Esc to exit\n",
    "            if key == 27:\n",
    "                break\n",
    "\n",
    "        self.soundOff()\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "obj = Project()\n",
    "video_path = (input(\"Enter path of video: \") or 0)\n",
    "obj.drowsinessDetectionSystem(video_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate Video (Manual Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import cv2\n",
    "import xlsxwriter\n",
    "\n",
    "class AnnotDataset:\n",
    "\n",
    "    def AnnotateDataset(self, video_path):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "        n = video_path.split(\"\\\\\")[-1]\n",
    "        n = n.split(\".\")[0]\n",
    "        workbook = xlsxwriter.Workbook(\"Testing Dataset\\\\Annotation\\\\\" + n + \".xlsx\")\n",
    "        worksheet = workbook.add_worksheet()\n",
    "        worksheet.write('A1', 'Frame Number')\n",
    "        worksheet.write('B1', 'Drowsy Status')\n",
    "\n",
    "        frame_count = 0\n",
    "        font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:     # If no frame is detected then stop\n",
    "                break\n",
    "\n",
    "            frame_count += 1\n",
    "            frame = cv2.flip(frame, 1)\n",
    "\n",
    "            key = cv2.waitKey(75) \n",
    "            if key == 27:   # Press Esc to exit\n",
    "                break\n",
    "            elif key == 100:    # Press d to enter drowsy state\n",
    "                worksheet.write('B'+str(frame_count+1), 1)\n",
    "                cv2.putText(frame, \"Drowsy!\", (250, 50), font, 1, (255, 0, 0))\n",
    "            else:\n",
    "                worksheet.write('B'+str(frame_count+1), 0)\n",
    "                cv2.putText(frame, \"Active :)\", (250, 50), font, 1, (31, 163, 21))\n",
    "            worksheet.write('A'+str(frame_count+1), frame_count)\n",
    "\n",
    "            cv2.imshow(\"Annotate Dataset\", frame) # Display frame\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        workbook.close()\n",
    "\n",
    "obj = AnnotDataset()\n",
    "video_path = input(\"Enter path of video: \")\n",
    "obj.AnnotateDataset(video_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate a video using Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import os\n",
    "import xlsxwriter\n",
    "from math import hypot\n",
    "\n",
    "\n",
    "class AnnotVideoAlgo:\n",
    "\n",
    "    def aspect_ratio(self, landmark_list, face_landmarks):   # Calculate Aspect Ratio\n",
    "        n = len(landmark_list)\n",
    "\n",
    "        # Calculate horizontal length\n",
    "        left_point = face_landmarks[landmark_list[0]] # (x, y)\n",
    "        right_point = face_landmarks[landmark_list[n//2]]\n",
    "        hor_length = hypot((left_point[0] - right_point[0]), (left_point[1] - right_point[1]))\n",
    "\n",
    "        top = list()    # Co-ordinates of the upper part    \n",
    "        bottom = list() # Co-ordinates of the lower part\n",
    "\n",
    "        for i in range(1, n//2):\n",
    "            top.append(face_landmarks[landmark_list[i]])\n",
    "            bottom.append(face_landmarks[landmark_list[-1*i]])\n",
    "\n",
    "        ver_lengths = list()\n",
    "        for i in range(len(top)):   # Calculate vertical lengths\n",
    "            d = hypot((top[i][0] - bottom[i][0]), (top[i][1] - bottom[i][1]))\n",
    "            ver_lengths.append(d)\n",
    "\n",
    "        s = len(ver_lengths)\n",
    "        ratio = sum(ver_lengths) / (s * hor_length) # Calculate aspect ratio\n",
    "        return ratio\n",
    "\n",
    "    def landmarkCoordinates(self, facelandmarks, image):\n",
    "        coord = list()\n",
    "        ih, iw, ic = image.shape # image height, image width, image channels\n",
    "        for lm in facelandmarks:\n",
    "            x, y = int(lm.x*iw), int(lm.y*ih)\n",
    "            coord.append((x, y))\n",
    "        return coord\n",
    "    \n",
    "    def AnnotateVideoAlgo(self, vid_path):\n",
    "        video = os.fsdecode(vid_path)\n",
    "        cap = cv2.VideoCapture(vid_path)\n",
    "\n",
    "        n = video.split(\".\")[0]\n",
    "        n = n.replace('\\\\Videos\\\\', '\\\\Annotation\\\\')\n",
    "        workbook = xlsxwriter.Workbook(n + \".xlsx\")\n",
    "        worksheet = workbook.add_worksheet()\n",
    "        worksheet.write('A1', 'Frame Number')\n",
    "        worksheet.write('B1', 'Drowsy Status')\n",
    "        \n",
    "        frame_count = 0\n",
    "\n",
    "        mpFaceMesh = mp.solutions.face_mesh\n",
    "        faceMesh = mpFaceMesh.FaceMesh()\n",
    "        \n",
    "        eye_close_count = 0\n",
    "        mouth_open_count = 0\n",
    "        font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "        max_ear = 0\n",
    "        min_ear = 1\n",
    "        per = 40\n",
    "        threshold_ear = 0.25\n",
    "        threshold_mar = 0.35\n",
    "        max_frame_count = 20\n",
    "\n",
    "        le = [33, 246, 161, 160, 159, 158, 157, 173,\n",
    "            133, 155, 154, 153, 145, 144, 163, 7]\n",
    "        re = [362, 398, 384, 385, 386, 387, 388, 466,\n",
    "            263, 249, 390, 373, 374, 380, 381, 382]\n",
    "\n",
    "        il = [78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "            308, 324, 318, 402, 317, 14, 87, 178, 88, 95]\n",
    "        ol = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n",
    "            291, 375, 321, 405, 314, 17, 84, 181, 91, 146]\n",
    "        \n",
    "        while True:\n",
    "            success, frame = cap.read()\n",
    "            if not success:     # If no frame is detected then stop\n",
    "                break\n",
    "            if vid_path.split('.')[-1] == \"mp4\":\n",
    "                frame = cv2.resize(frame, (1600, 900))\n",
    "            frame_count += 1\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            results = faceMesh.process(frame)  # Detect faces\n",
    "\n",
    "\n",
    "            if results.multi_face_landmarks:\n",
    "                face = results.multi_face_landmarks[0]     # Consider only 1st detected face\n",
    "                face_landmarks = self.landmarkCoordinates(face.landmark, frame)   # Get facial landmarks\n",
    "\n",
    "                left_eye_ratio = self.aspect_ratio(le, face_landmarks) # 7vertical 1horizontal\n",
    "                right_eye_ratio = self.aspect_ratio(re, face_landmarks) # 7v 1h\n",
    "                eye_aspect_ratio = (left_eye_ratio + right_eye_ratio) / 2   # Calculate eye aspect ratio\n",
    "\n",
    "                inner_lip_ratio = self.aspect_ratio(il, face_landmarks) # 9v  1h\n",
    "                outter_lip_ratio = self.aspect_ratio(ol, face_landmarks) # 9v 1h\n",
    "                mouth_aspect_ratio = (inner_lip_ratio + outter_lip_ratio) / 2 # Calculate mouth aspect ratio\n",
    "\n",
    "                max_ear = max(max_ear, eye_aspect_ratio)\n",
    "                min_ear = min(min_ear, eye_aspect_ratio)\n",
    "                diff = max_ear - min_ear\n",
    "                threshold_ear = min_ear + diff * per / 100      # Calculate threshold eye aspect ratio\n",
    "\n",
    "                if eye_aspect_ratio < threshold_ear:\n",
    "                    eye_close_count += 1\n",
    "                else:\n",
    "                    eye_close_count = 0\n",
    "\n",
    "                if mouth_aspect_ratio > threshold_mar:\n",
    "                    mouth_open_count += 1\n",
    "                else:\n",
    "                    mouth_open_count = 0\n",
    "\n",
    "\n",
    "                if eye_close_count < max_frame_count and mouth_open_count < max_frame_count:\n",
    "                    worksheet.write('B'+str(frame_count+1), 0)\n",
    "                    cv2.putText(frame, \"Active :)\", (250, 50), font, 1, (31, 163, 21))\n",
    "\n",
    "                else:\n",
    "                    worksheet.write('B'+str(frame_count+1), 1)\n",
    "                    cv2.putText(frame, \"Drowsy!\", (250, 50), font, 1, (255, 0, 0))\n",
    "            else:\n",
    "                worksheet.write('B'+str(frame_count+1), 0)\n",
    "                    \n",
    "            worksheet.write('A'+str(frame_count+1), frame_count)\n",
    "            cv2.imshow(\"Annotate Video Using Algorithm\", frame) # Display frame\n",
    "\n",
    "            key = cv2.waitKey(20)    # Press Esc to exit\n",
    "            if key == 27:\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        workbook.close()\n",
    "\n",
    "obj = AnnotVideoAlgo()\n",
    "vid_path = input(\"Enter path of video: \")\n",
    "obj.AnnotateVideoAlgo(vid_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate all videos from directory using Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import os\n",
    "import xlsxwriter\n",
    "from math import hypot\n",
    "\n",
    "\n",
    "class AnnotVideoAlgo:\n",
    "\n",
    "    def aspect_ratio(self, landmark_list, face_landmarks):   # Calculate Aspect Ratio\n",
    "        n = len(landmark_list)\n",
    "\n",
    "        # Calculate horizontal length\n",
    "        left_point = face_landmarks[landmark_list[0]] # (x, y)\n",
    "        right_point = face_landmarks[landmark_list[n//2]]\n",
    "        hor_length = hypot((left_point[0] - right_point[0]), (left_point[1] - right_point[1]))\n",
    "\n",
    "        top = list()    # Co-ordinates of the upper part    \n",
    "        bottom = list() # Co-ordinates of the lower part\n",
    "\n",
    "        for i in range(1, n//2):\n",
    "            top.append(face_landmarks[landmark_list[i]])\n",
    "            bottom.append(face_landmarks[landmark_list[-1*i]])\n",
    "\n",
    "        ver_lengths = list()\n",
    "        for i in range(len(top)):   # Calculate vertical lengths\n",
    "            d = hypot((top[i][0] - bottom[i][0]), (top[i][1] - bottom[i][1]))\n",
    "            ver_lengths.append(d)\n",
    "\n",
    "        s = len(ver_lengths)\n",
    "        ratio = sum(ver_lengths) / (s * hor_length) # Calculate aspect ratio\n",
    "        return ratio\n",
    "\n",
    "    def landmarkCoordinates(self, facelandmarks, image):\n",
    "        coord = list()\n",
    "        ih, iw, ic = image.shape # image height, image width, image channels\n",
    "        for lm in facelandmarks:\n",
    "            x, y = int(lm.x*iw), int(lm.y*ih)\n",
    "            coord.append((x, y))\n",
    "        return coord\n",
    "    \n",
    "    def AnnotateVideoAlgo(self, videos_dir):\n",
    "        for f1 in os.listdir(videos_dir):\n",
    "            video = os.fsdecode(f1)\n",
    "            cap = cv2.VideoCapture(videos_dir + \"\\\\\" + video)\n",
    "\n",
    "            n = video.split(\".\")[0]\n",
    "            workbook = xlsxwriter.Workbook(\"Testing Dataset\\\\Annotation\\\\\" + n + \".xlsx\")\n",
    "            worksheet = workbook.add_worksheet()\n",
    "            worksheet.write('A1', 'Frame Number')\n",
    "            worksheet.write('B1', 'Drowsy Status')\n",
    "            \n",
    "            frame_count = 0\n",
    "\n",
    "            mpFaceMesh = mp.solutions.face_mesh\n",
    "            faceMesh = mpFaceMesh.FaceMesh()\n",
    "            \n",
    "            eye_close_count = 0\n",
    "            mouth_open_count = 0\n",
    "            font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "            max_ear = 0\n",
    "            min_ear = 1\n",
    "            per = 40\n",
    "            threshold_ear = 0.25\n",
    "            threshold_mar = 0.35\n",
    "            max_frame_count = 20\n",
    "\n",
    "            le = [33, 246, 161, 160, 159, 158, 157, 173,\n",
    "                133, 155, 154, 153, 145, 144, 163, 7]\n",
    "            re = [362, 398, 384, 385, 386, 387, 388, 466,\n",
    "                263, 249, 390, 373, 374, 380, 381, 382]\n",
    "\n",
    "            il = [78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "                308, 324, 318, 402, 317, 14, 87, 178, 88, 95]\n",
    "            ol = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n",
    "                291, 375, 321, 405, 314, 17, 84, 181, 91, 146]\n",
    "            \n",
    "            while True:\n",
    "                success, frame = cap.read()\n",
    "                if not success:     # If no frame is detected then stop\n",
    "                    break\n",
    "                if video_path.split('.')[-1] == \"mp4\":\n",
    "                    frame = cv2.resize(frame, (1600, 900))\n",
    "                frame_count += 1\n",
    "                frame = cv2.flip(frame, 1)\n",
    "                results = faceMesh.process(frame)  # Detect faces\n",
    "\n",
    "\n",
    "                if results.multi_face_landmarks:\n",
    "                    face = results.multi_face_landmarks[0]     # Consider only 1st detected face\n",
    "                    face_landmarks = self.landmarkCoordinates(face.landmark, frame)   # Get facial landmarks\n",
    "\n",
    "                    left_eye_ratio = self.aspect_ratio(le, face_landmarks) # 7vertical 1horizontal\n",
    "                    right_eye_ratio = self.aspect_ratio(re, face_landmarks) # 7v 1h\n",
    "                    eye_aspect_ratio = (left_eye_ratio + right_eye_ratio) / 2   # Calculate eye aspect ratio\n",
    "\n",
    "                    inner_lip_ratio = self.aspect_ratio(il, face_landmarks) # 9v  1h\n",
    "                    outter_lip_ratio = self.aspect_ratio(ol, face_landmarks) # 9v 1h\n",
    "                    mouth_aspect_ratio = (inner_lip_ratio + outter_lip_ratio) / 2 # Calculate mouth aspect ratio\n",
    "\n",
    "                    max_ear = max(max_ear, eye_aspect_ratio)\n",
    "                    min_ear = min(min_ear, eye_aspect_ratio)\n",
    "                    diff = max_ear - min_ear\n",
    "                    threshold_ear = min_ear + diff * per / 100      # Calculate threshold eye aspect ratio\n",
    "\n",
    "                    if eye_aspect_ratio < threshold_ear:\n",
    "                        eye_close_count += 1\n",
    "                    else:\n",
    "                        eye_close_count = 0\n",
    "\n",
    "                    if mouth_aspect_ratio > threshold_mar:\n",
    "                        mouth_open_count += 1\n",
    "                    else:\n",
    "                        mouth_open_count = 0\n",
    "\n",
    "\n",
    "                    if eye_close_count < max_frame_count and mouth_open_count < max_frame_count:\n",
    "                        worksheet.write('B'+str(frame_count+1), 0)\n",
    "                        cv2.putText(frame, \"Active :)\", (250, 50), font, 1, (31, 163, 21))\n",
    "\n",
    "                    else:\n",
    "                        worksheet.write('B'+str(frame_count+1), 1)\n",
    "                        cv2.putText(frame, \"Drowsy!\", (250, 50), font, 1, (255, 0, 0))\n",
    "                else:\n",
    "                    worksheet.write('B'+str(frame_count+1), 0)\n",
    "                      \n",
    "                worksheet.write('A'+str(frame_count+1), frame_count)\n",
    "                cv2.imshow(\"Annotate Video Using Algorithm\", frame) # Display frame\n",
    "\n",
    "                key = cv2.waitKey(20)    # Press Esc to exit\n",
    "                if key == 27:\n",
    "                    break\n",
    "\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            workbook.close()\n",
    "\n",
    "obj = AnnotVideoAlgo()\n",
    "video_dir = input(\"Enter path of videos directory: \")\n",
    "obj.AnnotateVideoAlgo(video_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create combined result file to calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for video FemaleNoGlasses.avi is already present.\n",
      "Data for video P1043124_720.mp4 is already present.\n"
     ]
    }
   ],
   "source": [
    "# import the necessary libraries\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from math import hypot\n",
    "\n",
    "class Predict:\n",
    "    \n",
    "    def aspect_ratio(self, landmark_list, face_landmarks):   # Calculate Aspect Ratio\n",
    "        n = len(landmark_list)\n",
    "\n",
    "        # Calculate horizontal length\n",
    "        left_point = face_landmarks[landmark_list[0]] # (x, y)\n",
    "        right_point = face_landmarks[landmark_list[n//2]]\n",
    "        hor_length = hypot((left_point[0] - right_point[0]), (left_point[1] - right_point[1]))\n",
    "\n",
    "        top = list()    # Co-ordinates of the upper part    \n",
    "        bottom = list() # Co-ordinates of the lower part\n",
    "\n",
    "        for i in range(1, n//2):\n",
    "            top.append(face_landmarks[landmark_list[i]])\n",
    "            bottom.append(face_landmarks[landmark_list[-1*i]])\n",
    "\n",
    "        ver_lengths = list()\n",
    "        for i in range(len(top)):   # Calculate vertical lengths\n",
    "            d = hypot((top[i][0] - bottom[i][0]), (top[i][1] - bottom[i][1]))\n",
    "            ver_lengths.append(d)\n",
    "\n",
    "        s = len(ver_lengths)\n",
    "        ratio = sum(ver_lengths) / (s * hor_length) # Calculate aspect ratio\n",
    "        return ratio\n",
    "\n",
    "    def landmarkCoordinates(self, facelandmarks, image):\n",
    "        coord = list()\n",
    "        ih, iw, ic = image.shape # image height, image width, image channels\n",
    "        for lm in facelandmarks:\n",
    "            x, y = int(lm.x*iw), int(lm.y*ih)\n",
    "            coord.append((x, y))\n",
    "        return coord\n",
    "\n",
    "    def pred(self, dir1, dir2):\n",
    "\n",
    "        data_present = pd.read_excel(\"Testing Dataset\\\\Results.xlsx\")[\"Video\"].unique()\n",
    "\n",
    "        for (f1, f2) in zip(os.listdir(dir1), os.listdir(dir2)):\n",
    "            file_name = os.fsdecode(f1)\n",
    "            annot_name = os.fsdecode(f2)\n",
    "\n",
    "            if file_name in data_present:\n",
    "                print(\"Data for video\", file_name, \"is already present.\")\n",
    "                continue\n",
    "\n",
    "            if file_name.split('.')[0] == annot_name.split('.')[0]: \n",
    "                video_path = os.path.join(dir1, file_name)\n",
    "                annot_path = os.path.join(dir2, annot_name)\n",
    "\n",
    "                cap = cv2.VideoCapture(video_path)\n",
    "                frame_count = 0\n",
    "\n",
    "                mpFaceMesh = mp.solutions.face_mesh\n",
    "                faceMesh = mpFaceMesh.FaceMesh()\n",
    "                    \n",
    "                eye_close_count = 0\n",
    "                mouth_open_count = 0\n",
    "                font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "                yawn_count = 0\n",
    "                yawning = False\n",
    "                drowsy_count = 0 \n",
    "                drowsy = False\n",
    "\n",
    "                max_ear = 0\n",
    "                min_ear = 1\n",
    "                per = 40\n",
    "                threshold_ear = 0.25\n",
    "                threshold_mar = 0.35\n",
    "                max_frame_count = 20\n",
    "\n",
    "                le = [33, 246, 161, 160, 159, 158, 157, 173,\n",
    "                    133, 155, 154, 153, 145, 144, 163, 7]\n",
    "                re = [362, 398, 384, 385, 386, 387, 388, 466,\n",
    "                    263, 249, 390, 373, 374, 380, 381, 382]\n",
    "\n",
    "                il = [78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "                    308, 324, 318, 402, 317, 14, 87, 178, 88, 95]\n",
    "                ol = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n",
    "                    291, 375, 321, 405, 314, 17, 84, 181, 91, 146]\n",
    "\n",
    "                df = pd.read_excel(annot_path)\n",
    "                actual = df[\"Drowsy Status\"].to_list()\n",
    "                predicted = list()\n",
    "\n",
    "                while True:\n",
    "                    success, frame = cap.read()\n",
    "                    if not success:     # If no frame is detected then stop\n",
    "                        break\n",
    "                    if video_path.split('.')[-1] == \"mp4\":\n",
    "                        frame = cv2.resize(frame, (1600, 900))\n",
    "                    frame_count += 1\n",
    "                    frame = cv2.flip(frame, 1)\n",
    "                    results = faceMesh.process(frame)  # Detect faces\n",
    "\n",
    "\n",
    "                    if results.multi_face_landmarks:\n",
    "                        face = results.multi_face_landmarks[0]     # Consider only 1st detected face\n",
    "                        face_landmarks = self.landmarkCoordinates(face.landmark, frame)   # Get facial landmarks\n",
    "\n",
    "                        left_eye_ratio = self.aspect_ratio(le, face_landmarks) # 7vertical 1horizontal\n",
    "                        right_eye_ratio = self.aspect_ratio(re, face_landmarks) # 7v 1h\n",
    "                        eye_aspect_ratio = (left_eye_ratio + right_eye_ratio) / 2   # Calculate eye aspect ratio\n",
    "\n",
    "                        inner_lip_ratio = self.aspect_ratio(il, face_landmarks) # 9v  1h\n",
    "                        outter_lip_ratio = self.aspect_ratio(ol, face_landmarks) # 9v 1h\n",
    "                        mouth_aspect_ratio = (inner_lip_ratio + outter_lip_ratio) / 2 # Calculate mouth aspect ratio\n",
    "\n",
    "                        max_ear = max(max_ear, eye_aspect_ratio)\n",
    "                        min_ear = min(min_ear, eye_aspect_ratio)\n",
    "                        diff = max_ear - min_ear\n",
    "                        threshold_ear = min_ear + diff * per / 100      # Calculate threshold eye aspect ratio\n",
    "\n",
    "                        if eye_aspect_ratio < threshold_ear:\n",
    "                            eye_close_count += 1\n",
    "                        else:\n",
    "                            eye_close_count = 0\n",
    "\n",
    "                        if mouth_aspect_ratio > threshold_mar:\n",
    "                            mouth_open_count += 1\n",
    "                        else:\n",
    "                            mouth_open_count = 0\n",
    "\n",
    "\n",
    "                        if eye_close_count < max_frame_count and mouth_open_count < max_frame_count:\n",
    "                            predicted.append(0)\n",
    "                        else:\n",
    "                            predicted.append(1)\n",
    "                            \n",
    "                    else:\n",
    "                        predicted.append(0)\n",
    "\n",
    "                    cv2.imshow(\"Create combined result file to calculate accuracy\", frame) # Display frame\n",
    "\n",
    "                    key = cv2.waitKey(20)    # Press Esc to exit\n",
    "                    if key == 27:\n",
    "                        break\n",
    "\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "\n",
    "                if len(actual) == len(predicted):\n",
    "                    df2 = pd.DataFrame({\"Video\": file_name, \"Frame Number\": list(range(1, frame_count+1)), \"Actual\": actual, \"Predicted\": predicted})\n",
    "                    workbook = openpyxl.load_workbook('Testing Dataset\\Results.xlsx')\n",
    "                    worksheet = workbook['Sheet1']\n",
    "                    data = df2.values.tolist()\n",
    "                    for row in data:\n",
    "                        worksheet.append(row)\n",
    "                    workbook.save('Testing Dataset\\Results.xlsx')\n",
    "                else:\n",
    "                    print(\"Error in video\", file_name)\n",
    "            else:\n",
    "                print(\"Error in video\", file_name)\n",
    "\n",
    "obj = Predict()\n",
    "obj.pred(\"Testing Dataset\\\\Videos\\\\\", \"Testing Dataset\\\\Annotation\\\\\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Performace of Model using One Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# import the necessary libraries\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from math import hypot\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "class Test:\n",
    "\n",
    "    def aspect_ratio(self, landmark_list, face_landmarks):   # Calculate Aspect Ratio\n",
    "        n = len(landmark_list)\n",
    "\n",
    "        # Calculate horizontal length\n",
    "        left_point = face_landmarks[landmark_list[0]] # (x, y)\n",
    "        right_point = face_landmarks[landmark_list[n//2]]\n",
    "        hor_length = hypot((left_point[0] - right_point[0]), (left_point[1] - right_point[1]))\n",
    "\n",
    "        top = list()    # Co-ordinates of the upper part    \n",
    "        bottom = list() # Co-ordinates of the lower part\n",
    "\n",
    "        for i in range(1, n//2):\n",
    "            top.append(face_landmarks[landmark_list[i]])\n",
    "            bottom.append(face_landmarks[landmark_list[-1*i]])\n",
    "\n",
    "        ver_lengths = list()\n",
    "        for i in range(len(top)):   # Calculate vertical lengths\n",
    "            d = hypot((top[i][0] - bottom[i][0]), (top[i][1] - bottom[i][1]))\n",
    "            ver_lengths.append(d)\n",
    "\n",
    "        s = len(ver_lengths)\n",
    "        ratio = sum(ver_lengths) / (s * hor_length) # Calculate aspect ratio\n",
    "        return ratio\n",
    "\n",
    "    def landmarkCoordinates(self, facelandmarks, image):\n",
    "        coord = list()\n",
    "        ih, iw, ic = image.shape # image height, image width, image channels\n",
    "        for lm in facelandmarks:\n",
    "            x, y = int(lm.x*iw), int(lm.y*ih)\n",
    "            coord.append((x, y))\n",
    "        return coord\n",
    "\n",
    "    def testing(self, video_path):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_count = 0\n",
    "\n",
    "        mpFaceMesh = mp.solutions.face_mesh\n",
    "        faceMesh = mpFaceMesh.FaceMesh()\n",
    "            \n",
    "        eye_close_count = 0\n",
    "        mouth_open_count = 0\n",
    "        font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "        yawn_count = 0\n",
    "        yawning = False\n",
    "        drowsy_count = 0 \n",
    "        drowsy = False\n",
    "\n",
    "        max_ear = 0\n",
    "        min_ear = 1\n",
    "        per = 40\n",
    "        threshold_ear = 0.25\n",
    "        threshold_mar = 0.35\n",
    "        max_frame_count = 20\n",
    "\n",
    "        le = [33, 246, 161, 160, 159, 158, 157, 173,\n",
    "            133, 155, 154, 153, 145, 144, 163, 7]\n",
    "        re = [362, 398, 384, 385, 386, 387, 388, 466,\n",
    "            263, 249, 390, 373, 374, 380, 381, 382]\n",
    "\n",
    "        il = [78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "            308, 324, 318, 402, 317, 14, 87, 178, 88, 95]\n",
    "        ol = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n",
    "            291, 375, 321, 405, 314, 17, 84, 181, 91, 146]\n",
    "\n",
    "        n = video_path.split(\"\\\\\")[-1]\n",
    "        n = n.split(\".\")[0]\n",
    "        df = pd.read_excel(\"Testing Dataset\\\\Annotation\\\\\" + n + \".xlsx\")\n",
    "        actual = df[\"Drowsy Status\"].to_list()\n",
    "        predicted = list()\n",
    "\n",
    "        while True:\n",
    "            success, frame = cap.read()\n",
    "            if not success:     # If no frame is detected then stop\n",
    "                break\n",
    "            if video_path.split('.')[-1] == \"mp4\":\n",
    "                frame = cv2.resize(frame, (1600, 900))\n",
    "            frame_count += 1\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            results = faceMesh.process(frame)  # Detect faces\n",
    "\n",
    "\n",
    "            if results.multi_face_landmarks:\n",
    "                face = results.multi_face_landmarks[0]     # Consider only 1st detected face\n",
    "                face_landmarks = self.landmarkCoordinates(face.landmark, frame)   # Get facial landmarks\n",
    "\n",
    "                left_eye_ratio = self.aspect_ratio(le, face_landmarks) # 7vertical 1horizontal\n",
    "                right_eye_ratio = self.aspect_ratio(re, face_landmarks) # 7v 1h\n",
    "                eye_aspect_ratio = (left_eye_ratio + right_eye_ratio) / 2   # Calculate eye aspect ratio\n",
    "\n",
    "                inner_lip_ratio = self.aspect_ratio(il, face_landmarks) # 9v  1h\n",
    "                outter_lip_ratio = self.aspect_ratio(ol, face_landmarks) # 9v 1h\n",
    "                mouth_aspect_ratio = (inner_lip_ratio + outter_lip_ratio) / 2 # Calculate mouth aspect ratio\n",
    "\n",
    "                max_ear = max(max_ear, eye_aspect_ratio)\n",
    "                min_ear = min(min_ear, eye_aspect_ratio)\n",
    "                diff = max_ear - min_ear\n",
    "                threshold_ear = min_ear + diff * per / 100      # Calculate threshold eye aspect ratio\n",
    "\n",
    "                if eye_aspect_ratio < threshold_ear:\n",
    "                    eye_close_count += 1\n",
    "                else:\n",
    "                    eye_close_count = 0\n",
    "\n",
    "                if mouth_aspect_ratio > threshold_mar:\n",
    "                    mouth_open_count += 1\n",
    "                else:\n",
    "                    mouth_open_count = 0\n",
    "\n",
    "\n",
    "                if eye_close_count < max_frame_count and mouth_open_count < max_frame_count:\n",
    "                    predicted.append(0)\n",
    "                    cv2.putText(frame, \"Predicted State => Active :)\", (400, 50), font, 0.5, (31, 163, 21))\n",
    "                else:\n",
    "                    predicted.append(1)\n",
    "                    cv2.putText(frame, \"Predicted State => Drowsy!\", (400, 50), font, 0.5, (255, 0, 0))\n",
    "                    \n",
    "                if actual[len(predicted)-1] == 1:\n",
    "                    cv2.putText(frame, \"Actual State => Drowsy!\", (10, 50), font, 0.5, (255, 0, 0))\n",
    "                else:\n",
    "                    cv2.putText(frame, \"Actual State=> Active :)\", (10, 50), font, 0.5, (31, 163, 21))\n",
    "                    \n",
    "            else:\n",
    "                predicted.append(0)\n",
    "\n",
    "            cv2.imshow(\"Testing Performace of Model using One Video\", frame) # Display frame\n",
    "\n",
    "            key = cv2.waitKey(20)    # Press Esc to exit\n",
    "            if key == 27:\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        if len(actual) != len(predicted):\n",
    "            print(\"Error in\", video_path.split(\"\\\\\")[-1])\n",
    "            return\n",
    "\n",
    "        cm = confusion_matrix(actual, predicted)\n",
    "        plt.figure()\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.show()\n",
    "\n",
    "        # Accuracy Score = (TP + TN) / (TP + FN + TN + FP)\n",
    "        print('Accuracy:', round(accuracy_score(actual, predicted), 5))\n",
    "\n",
    "        # Precision Score = TP / (FP + TP)\n",
    "        print('Precision:', round(precision_score(actual, predicted), 5))\n",
    "\n",
    "        # Recall Score = TP / (FN + TP)    \n",
    "        print('Recall:', round(recall_score(actual, predicted), 5))\n",
    "\n",
    "        # F1 Score = 2 * Precision Score * Recall Score / (Precision Score + Recall Score)\n",
    "        print('F1 Score:', round(f1_score(actual, predicted), 5))\n",
    "\n",
    "obj = Test()\n",
    "video_path = input(\"Enter path of video: \")\n",
    "obj.testing(video_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Overall Accuracy of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95202\n",
      "Precision: 0.83548\n",
      "Recall: 0.78219\n",
      "F1 Score: 0.80796\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "df = pd.read_excel(\"Testing Dataset\\\\Results.xlsx\")\n",
    "actual = df[\"Actual\"].to_list()\n",
    "predicted = df[\"Predicted\"].to_list()\n",
    "\n",
    "if len(actual) != len(predicted):\n",
    "    print(\"Error in data\")\n",
    "    exit(0)\n",
    "\n",
    "cm = confusion_matrix(actual, predicted)\n",
    "plt.figure()\n",
    "plt.title(\"Confusion Matrix\")\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# Accuracy Score = (TP + TN) / (TP + FN + TN + FP)\n",
    "print('Accuracy:', round(accuracy_score(actual, predicted), 5))\n",
    "\n",
    "# Precision Score = TP / (FP + TP)\n",
    "print('Precision:', round(precision_score(actual, predicted), 5))\n",
    "\n",
    "# Recall Score = TP / (FN + TP)    \n",
    "print('Recall:', round(recall_score(actual, predicted), 5))\n",
    "\n",
    "# F1 Score = 2 * Precision Score * Recall Score / (Precision Score + Recall Score)\n",
    "print('F1 Score:', round(f1_score(actual, predicted), 5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete data of a video from Results.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "video = input(\"Enter name of video (with extension): \")\n",
    "df = pd.read_excel(\"Testing Dataset\\\\Results.xlsx\")\n",
    "df = df[df[\"Video\"] != video]\n",
    "\n",
    "df.to_excel(\"Testing Dataset\\\\Results.xlsx\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
