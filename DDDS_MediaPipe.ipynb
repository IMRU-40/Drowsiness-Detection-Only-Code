{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver Drowsiness Detection System\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MediaPipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import multiprocessing\n",
    "from math import hypot\n",
    "from playsound import playsound\n",
    "\n",
    "\n",
    "class Project:\n",
    "    def __init__(self):     # Constructor\n",
    "        self.p = multiprocessing.Process()\n",
    "\n",
    "    def soundOn(self):      # Play Sound\n",
    "        if not self.p.is_alive():\n",
    "            self.p = multiprocessing.Process(\n",
    "                target=playsound, args=(\"alarm.mp3\",))\n",
    "            self.p.start()\n",
    "\n",
    "    def soundOff(self):     # Stop Sound\n",
    "        if self.p.is_alive():\n",
    "            self.p.terminate()\n",
    "\n",
    "    def aspect_ratio(self, landmark_list, face_landmarks):   # Calculate Aspect Ratio\n",
    "        n = len(landmark_list)\n",
    "\n",
    "        # Calculate horizontal length\n",
    "        left_point = face_landmarks[landmark_list[0]]  # (x, y)\n",
    "        right_point = face_landmarks[landmark_list[n//2]]\n",
    "        hor_length = hypot(\n",
    "            (left_point[0] - right_point[0]), (left_point[1] - right_point[1]))\n",
    "\n",
    "        top = list()    # Co-ordinates of the upper part\n",
    "        bottom = list()  # Co-ordinates of the lower part\n",
    "\n",
    "        for i in range(1, n//2):\n",
    "            top.append(face_landmarks[landmark_list[i]])\n",
    "            bottom.append(face_landmarks[landmark_list[-1*i]])\n",
    "\n",
    "        ver_lengths = list()\n",
    "        for i in range(len(top)):   # Calculate vertical lengths\n",
    "            d = hypot((top[i][0] - bottom[i][0]), (top[i][1] - bottom[i][1]))\n",
    "            ver_lengths.append(d)\n",
    "\n",
    "        s = len(ver_lengths)\n",
    "        ratio = sum(ver_lengths) / (s * hor_length)  # Calculate aspect ratio\n",
    "        return ratio\n",
    "\n",
    "    def landmarkCoordinates(self, facelandmarks, image):\n",
    "        coord = list()\n",
    "        ih, iw, ic = image.shape  # image height, image width, image channels\n",
    "        for lm in facelandmarks:\n",
    "            x, y = int(lm.x*iw), int(lm.y*ih)\n",
    "            coord.append((x, y))\n",
    "        return coord\n",
    "\n",
    "    def save_jpeg_image(self, frame, folder_path, file_name):\n",
    "        # Encode the frame as a JPEG image\n",
    "        ret, jpeg = cv2.imencode('.jpg', frame)\n",
    "\n",
    "        # Convert the JPEG image to bytes\n",
    "        image_bytes = jpeg.tobytes()\n",
    "\n",
    "        # Create the folder if it doesn't exist\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "        # Write the image bytes to a file in the folder\n",
    "        with open(os.path.join(folder_path, file_name), 'wb') as f:\n",
    "            f.write(image_bytes)\n",
    "\n",
    "    def drowsinessDetectionSystem(self, video_path=0):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        pTime = 0\n",
    "\n",
    "        mpFaceMesh = mp.solutions.face_mesh\n",
    "        faceMesh = mpFaceMesh.FaceMesh()\n",
    "\n",
    "        eye_close_count = 0\n",
    "        mouth_open_count = 0\n",
    "        font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "        yawn_count = 0\n",
    "        yawning = False\n",
    "        drowsy_count = 0\n",
    "        drowsy = False\n",
    "\n",
    "        max_ear = 0\n",
    "        min_ear = 1\n",
    "        per = 40\n",
    "        threshold_ear = 0.25\n",
    "        threshold_mar = 0.35\n",
    "        max_frame_count = 20\n",
    "\n",
    "        frame_no = 0\n",
    "\n",
    "        le = [33, 246, 161, 160, 159, 158, 157, 173,\n",
    "              133, 155, 154, 153, 145, 144, 163, 7]\n",
    "        re = [362, 398, 384, 385, 386, 387, 388, 466,\n",
    "              263, 249, 390, 373, 374, 380, 381, 382]\n",
    "\n",
    "        il = [78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "              308, 324, 318, 402, 317, 14, 87, 178, 88, 95]\n",
    "        ol = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n",
    "              291, 375, 321, 405, 314, 17, 84, 181, 91, 146]\n",
    "\n",
    "        while True:\n",
    "            success, frame = cap.read()\n",
    "            if not success:     # If no frame is detected then stop\n",
    "                break\n",
    "\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            results = faceMesh.process(frame)  # Detect faces\n",
    "\n",
    "            cTime = time.time()\n",
    "            fps = 1/(cTime - pTime)\n",
    "            pTime = cTime\n",
    "            cv2.putText(frame, f\"FPS: {int(fps)}\",\n",
    "                        (10, 15), font, 0.5, (0, 0, 0))\n",
    "\n",
    "            if results.multi_face_landmarks:\n",
    "                # Consider only 1st detected face\n",
    "                face = results.multi_face_landmarks[0]\n",
    "                face_landmarks = self.landmarkCoordinates(\n",
    "                    face.landmark, frame)   # Get facial landmarks\n",
    "\n",
    "                left_eye_ratio = self.aspect_ratio(\n",
    "                    le, face_landmarks)  # 7vertical 1horizontal\n",
    "                right_eye_ratio = self.aspect_ratio(\n",
    "                    re, face_landmarks)  # 7v 1h\n",
    "                # Calculate eye aspect ratio\n",
    "                eye_aspect_ratio = (left_eye_ratio + right_eye_ratio) / 2\n",
    "                cv2.putText(frame, \"Cur EAR: \"+str(round(eye_aspect_ratio, 5)),\n",
    "                            (10, 30), font, 0.5, (0, 0, 0))\n",
    "                cv2.putText(frame, \"Thresh EAR: \"+str(round(threshold_ear, 5)),\n",
    "                            (10, 45), font, 0.5, (0, 0, 0))\n",
    "\n",
    "                cv2.putText(frame, \"Drowsy Count: \"+str(drowsy_count),\n",
    "                            (250, 15), font, 0.5, (0, 0, 0))\n",
    "\n",
    "                inner_lip_ratio = self.aspect_ratio(\n",
    "                    il, face_landmarks)  # 9v  1h\n",
    "                outter_lip_ratio = self.aspect_ratio(\n",
    "                    ol, face_landmarks)  # 9v 1h\n",
    "                # Calculate mouth aspect ratio\n",
    "                mouth_aspect_ratio = (inner_lip_ratio + outter_lip_ratio) / 2\n",
    "                cv2.putText(frame, \"Cur MAR: \"+str(round(mouth_aspect_ratio, 5)),\n",
    "                            (475, 15), font, 0.5, (0, 0, 0))\n",
    "                cv2.putText(frame, \"Thresh MAR: \"+str(round(threshold_mar, 5)),\n",
    "                            (475, 30), font, 0.5, (0, 0, 0))\n",
    "                cv2.putText(frame, \"Yawn Count: \"+str(yawn_count),\n",
    "                            (475, 45), font, 0.5, (0, 0, 0))\n",
    "\n",
    "                max_ear = max(max_ear, eye_aspect_ratio)\n",
    "                min_ear = min(min_ear, eye_aspect_ratio)\n",
    "                diff = max_ear - min_ear\n",
    "                # Calculate threshold eye aspect ratio\n",
    "                threshold_ear = min_ear + diff * per / 100\n",
    "\n",
    "                if eye_aspect_ratio < threshold_ear:\n",
    "                    eye_close_count += 1\n",
    "                else:\n",
    "                    eye_close_count = 0\n",
    "\n",
    "                if mouth_aspect_ratio > threshold_mar:\n",
    "                    mouth_open_count += 1\n",
    "                else:\n",
    "                    mouth_open_count = 0\n",
    "\n",
    "                if eye_close_count >= max_frame_count:\n",
    "                    cv2.putText(frame, \"Eyes Closed\", (10, 70),\n",
    "                                font, 0.75, (0, 0, 255))\n",
    "                if mouth_open_count >= max_frame_count:\n",
    "                    cv2.putText(frame, \"Yawning\", (475, 70),\n",
    "                                font, 0.75, (0, 0, 255))\n",
    "                    if not yawning:\n",
    "                        yawn_count += 1\n",
    "                        yawning = True\n",
    "                else:\n",
    "                    if yawning:\n",
    "                        yawning = False\n",
    "\n",
    "                # Get co-ordinates of rectangle in which face is detected\n",
    "                x1, y1 = face_landmarks[234][0], face_landmarks[10][1]\n",
    "                x2, y2 = face_landmarks[454][0], face_landmarks[152][1]\n",
    "\n",
    "                if eye_close_count < max_frame_count and mouth_open_count < max_frame_count:\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (31, 163, 21), 2)\n",
    "                    cv2.putText(frame, \"Active :)\", (250, 50),\n",
    "                                font, 1, (31, 163, 21))\n",
    "                    self.soundOff()\n",
    "                    if drowsy:\n",
    "                        drowsy = False\n",
    "                else:\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                    cv2.putText(frame, \"Drowsy!\", (250, 50),\n",
    "                                font, 1, (255, 0, 0))\n",
    "                    self.soundOn()\n",
    "                    if not drowsy:\n",
    "                        drowsy_count += 1\n",
    "                        drowsy = True\n",
    "\n",
    "                for i in le + re + il + ol:  # Plot facial landmarks\n",
    "                    (x, y) = (face_landmarks[i][0], face_landmarks[i][1])\n",
    "                    cv2.circle(frame, (x, y), 1, (255, 255, 255), -1)\n",
    "\n",
    "            else:\n",
    "                self.soundOff()\n",
    "\n",
    "            cv2.imshow(\"Driver Drowsiness Detection System\",\n",
    "                       frame)  # Display frame\n",
    "\n",
    "            frame_no += 1\n",
    "\n",
    "            # Save Image\n",
    "            folder_path = 'images'\n",
    "            file_name = f'my_image{frame_no}.jpg'\n",
    "            # self.save_jpeg_image(frame, folder_path, file_name)\n",
    "\n",
    "            key = cv2.waitKey(20)    # Press Esc to exit\n",
    "            if key == 27:\n",
    "                break\n",
    "\n",
    "        self.soundOff()\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "obj = Project()\n",
    "video_path = (input(\"Enter path of video: \") or 0)\n",
    "obj.drowsinessDetectionSystem(video_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate Video (Manual Method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import cv2\n",
    "import xlsxwriter\n",
    "\n",
    "\n",
    "class AnnotDataset:\n",
    "\n",
    "    def AnnotateDataset(self, video_path):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "        n = video_path.split(\"\\\\\")[-1]\n",
    "        n = n.split(\".\")[0]\n",
    "        workbook = xlsxwriter.Workbook(\n",
    "            \"Testing Dataset\\\\Annotation\\\\\" + n + \".xlsx\")\n",
    "        worksheet = workbook.add_worksheet()\n",
    "        worksheet.write('A1', 'Frame Number')\n",
    "        worksheet.write('B1', 'Drowsy Status')\n",
    "\n",
    "        frame_count = 0\n",
    "        font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:     # If no frame is detected then stop\n",
    "                break\n",
    "\n",
    "            frame_count += 1\n",
    "            frame = cv2.flip(frame, 1)\n",
    "\n",
    "            key = cv2.waitKey(75)\n",
    "            if key == 27:   # Press Esc to exit\n",
    "                break\n",
    "            elif key == 100:    # Press d to enter drowsy state\n",
    "                worksheet.write('B'+str(frame_count+1), 1)\n",
    "                cv2.putText(frame, \"Drowsy!\", (250, 50), font, 1, (255, 0, 0))\n",
    "            else:\n",
    "                worksheet.write('B'+str(frame_count+1), 0)\n",
    "                cv2.putText(frame, \"Active :)\", (250, 50),\n",
    "                            font, 1, (31, 163, 21))\n",
    "            worksheet.write('A'+str(frame_count+1), frame_count)\n",
    "\n",
    "            cv2.imshow(\"Annotate Dataset\", frame)  # Display frame\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        workbook.close()\n",
    "\n",
    "\n",
    "obj = AnnotDataset()\n",
    "video_path = input(\"Enter path of video: \")\n",
    "obj.AnnotateDataset(video_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate a video using Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import os\n",
    "import xlsxwriter\n",
    "from math import hypot\n",
    "\n",
    "\n",
    "class AnnotVideoAlgo:\n",
    "\n",
    "    def aspect_ratio(self, landmark_list, face_landmarks):   # Calculate Aspect Ratio\n",
    "        n = len(landmark_list)\n",
    "\n",
    "        # Calculate horizontal length\n",
    "        left_point = face_landmarks[landmark_list[0]]  # (x, y)\n",
    "        right_point = face_landmarks[landmark_list[n//2]]\n",
    "        hor_length = hypot(\n",
    "            (left_point[0] - right_point[0]), (left_point[1] - right_point[1]))\n",
    "\n",
    "        top = list()    # Co-ordinates of the upper part\n",
    "        bottom = list()  # Co-ordinates of the lower part\n",
    "\n",
    "        for i in range(1, n//2):\n",
    "            top.append(face_landmarks[landmark_list[i]])\n",
    "            bottom.append(face_landmarks[landmark_list[-1*i]])\n",
    "\n",
    "        ver_lengths = list()\n",
    "        for i in range(len(top)):   # Calculate vertical lengths\n",
    "            d = hypot((top[i][0] - bottom[i][0]), (top[i][1] - bottom[i][1]))\n",
    "            ver_lengths.append(d)\n",
    "\n",
    "        s = len(ver_lengths)\n",
    "        ratio = sum(ver_lengths) / (s * hor_length)  # Calculate aspect ratio\n",
    "        return ratio\n",
    "\n",
    "    def landmarkCoordinates(self, facelandmarks, image):\n",
    "        coord = list()\n",
    "        ih, iw, ic = image.shape  # image height, image width, image channels\n",
    "        for lm in facelandmarks:\n",
    "            x, y = int(lm.x*iw), int(lm.y*ih)\n",
    "            coord.append((x, y))\n",
    "        return coord\n",
    "\n",
    "    def AnnotateVideoAlgo(self, vid_path):\n",
    "        video = os.fsdecode(vid_path)\n",
    "        cap = cv2.VideoCapture(vid_path)\n",
    "\n",
    "        n = video.split(\".\")[0]\n",
    "        n = n.replace('\\\\Videos\\\\', '\\\\Annotation\\\\')\n",
    "        workbook = xlsxwriter.Workbook(n + \".xlsx\")\n",
    "        worksheet = workbook.add_worksheet()\n",
    "        worksheet.write('A1', 'Frame Number')\n",
    "        worksheet.write('B1', 'Drowsy Status')\n",
    "\n",
    "        frame_count = 0\n",
    "\n",
    "        mpFaceMesh = mp.solutions.face_mesh\n",
    "        faceMesh = mpFaceMesh.FaceMesh()\n",
    "\n",
    "        eye_close_count = 0\n",
    "        mouth_open_count = 0\n",
    "        font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "        max_ear = 0\n",
    "        min_ear = 1\n",
    "        per = 40\n",
    "        threshold_ear = 0.25\n",
    "        threshold_mar = 0.35\n",
    "        max_frame_count = 20\n",
    "\n",
    "        le = [33, 246, 161, 160, 159, 158, 157, 173,\n",
    "              133, 155, 154, 153, 145, 144, 163, 7]\n",
    "        re = [362, 398, 384, 385, 386, 387, 388, 466,\n",
    "              263, 249, 390, 373, 374, 380, 381, 382]\n",
    "\n",
    "        il = [78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "              308, 324, 318, 402, 317, 14, 87, 178, 88, 95]\n",
    "        ol = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n",
    "              291, 375, 321, 405, 314, 17, 84, 181, 91, 146]\n",
    "\n",
    "        while True:\n",
    "            success, frame = cap.read()\n",
    "            if not success:     # If no frame is detected then stop\n",
    "                break\n",
    "            if vid_path.split('.')[-1] == \"mp4\":\n",
    "                frame = cv2.resize(frame, (1600, 900))\n",
    "            frame_count += 1\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            results = faceMesh.process(frame)  # Detect faces\n",
    "\n",
    "            if results.multi_face_landmarks:\n",
    "                # Consider only 1st detected face\n",
    "                face = results.multi_face_landmarks[0]\n",
    "                face_landmarks = self.landmarkCoordinates(\n",
    "                    face.landmark, frame)   # Get facial landmarks\n",
    "\n",
    "                left_eye_ratio = self.aspect_ratio(\n",
    "                    le, face_landmarks)  # 7vertical 1horizontal\n",
    "                right_eye_ratio = self.aspect_ratio(\n",
    "                    re, face_landmarks)  # 7v 1h\n",
    "                # Calculate eye aspect ratio\n",
    "                eye_aspect_ratio = (left_eye_ratio + right_eye_ratio) / 2\n",
    "\n",
    "                inner_lip_ratio = self.aspect_ratio(\n",
    "                    il, face_landmarks)  # 9v  1h\n",
    "                outter_lip_ratio = self.aspect_ratio(\n",
    "                    ol, face_landmarks)  # 9v 1h\n",
    "                # Calculate mouth aspect ratio\n",
    "                mouth_aspect_ratio = (inner_lip_ratio + outter_lip_ratio) / 2\n",
    "\n",
    "                max_ear = max(max_ear, eye_aspect_ratio)\n",
    "                min_ear = min(min_ear, eye_aspect_ratio)\n",
    "                diff = max_ear - min_ear\n",
    "                # Calculate threshold eye aspect ratio\n",
    "                threshold_ear = min_ear + diff * per / 100\n",
    "\n",
    "                if eye_aspect_ratio < threshold_ear:\n",
    "                    eye_close_count += 1\n",
    "                else:\n",
    "                    eye_close_count = 0\n",
    "\n",
    "                if mouth_aspect_ratio > threshold_mar:\n",
    "                    mouth_open_count += 1\n",
    "                else:\n",
    "                    mouth_open_count = 0\n",
    "\n",
    "                if eye_close_count < max_frame_count and mouth_open_count < max_frame_count:\n",
    "                    worksheet.write('B'+str(frame_count+1), 0)\n",
    "                    cv2.putText(frame, \"Active :)\", (250, 50),\n",
    "                                font, 1, (31, 163, 21))\n",
    "\n",
    "                else:\n",
    "                    worksheet.write('B'+str(frame_count+1), 1)\n",
    "                    cv2.putText(frame, \"Drowsy!\", (250, 50),\n",
    "                                font, 1, (255, 0, 0))\n",
    "            else:\n",
    "                worksheet.write('B'+str(frame_count+1), 0)\n",
    "\n",
    "            worksheet.write('A'+str(frame_count+1), frame_count)\n",
    "            cv2.imshow(\"Annotate Video Using Algorithm\",\n",
    "                       frame)  # Display frame\n",
    "\n",
    "            key = cv2.waitKey(1)    # Press Esc to exit\n",
    "            if key == 27:\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        workbook.close()\n",
    "\n",
    "\n",
    "obj = AnnotVideoAlgo()\n",
    "vid_path = input(\"Enter path of video: \")\n",
    "obj.AnnotateVideoAlgo(vid_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate all videos from directory using Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import os\n",
    "import xlsxwriter\n",
    "from math import hypot\n",
    "\n",
    "\n",
    "class AnnotVideoAlgo:\n",
    "\n",
    "    def aspect_ratio(self, landmark_list, face_landmarks):   # Calculate Aspect Ratio\n",
    "        n = len(landmark_list)\n",
    "\n",
    "        # Calculate horizontal length\n",
    "        left_point = face_landmarks[landmark_list[0]]  # (x, y)\n",
    "        right_point = face_landmarks[landmark_list[n//2]]\n",
    "        hor_length = hypot(\n",
    "            (left_point[0] - right_point[0]), (left_point[1] - right_point[1]))\n",
    "\n",
    "        top = list()    # Co-ordinates of the upper part\n",
    "        bottom = list()  # Co-ordinates of the lower part\n",
    "\n",
    "        for i in range(1, n//2):\n",
    "            top.append(face_landmarks[landmark_list[i]])\n",
    "            bottom.append(face_landmarks[landmark_list[-1*i]])\n",
    "\n",
    "        ver_lengths = list()\n",
    "        for i in range(len(top)):   # Calculate vertical lengths\n",
    "            d = hypot((top[i][0] - bottom[i][0]), (top[i][1] - bottom[i][1]))\n",
    "            ver_lengths.append(d)\n",
    "\n",
    "        s = len(ver_lengths)\n",
    "        ratio = sum(ver_lengths) / (s * hor_length)  # Calculate aspect ratio\n",
    "        return ratio\n",
    "\n",
    "    def landmarkCoordinates(self, facelandmarks, image):\n",
    "        coord = list()\n",
    "        ih, iw, ic = image.shape  # image height, image width, image channels\n",
    "        for lm in facelandmarks:\n",
    "            x, y = int(lm.x*iw), int(lm.y*ih)\n",
    "            coord.append((x, y))\n",
    "        return coord\n",
    "\n",
    "    def AnnotateVideoAlgo(self, videos_dir):\n",
    "        for f1 in os.listdir(videos_dir):\n",
    "            video = os.fsdecode(f1)\n",
    "            cap = cv2.VideoCapture(videos_dir + \"\\\\\" + video)\n",
    "\n",
    "            n = video.split(\".\")[0]\n",
    "            workbook = xlsxwriter.Workbook(\n",
    "                \"Testing Dataset\\\\Annotation\\\\\" + n + \".xlsx\")\n",
    "            worksheet = workbook.add_worksheet()\n",
    "            worksheet.write('A1', 'Frame Number')\n",
    "            worksheet.write('B1', 'Drowsy Status')\n",
    "\n",
    "            frame_count = 0\n",
    "\n",
    "            mpFaceMesh = mp.solutions.face_mesh\n",
    "            faceMesh = mpFaceMesh.FaceMesh()\n",
    "\n",
    "            eye_close_count = 0\n",
    "            mouth_open_count = 0\n",
    "            font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "            max_ear = 0\n",
    "            min_ear = 1\n",
    "            per = 40\n",
    "            threshold_ear = 0.25\n",
    "            threshold_mar = 0.35\n",
    "            max_frame_count = 20\n",
    "\n",
    "            le = [33, 246, 161, 160, 159, 158, 157, 173,\n",
    "                  133, 155, 154, 153, 145, 144, 163, 7]\n",
    "            re = [362, 398, 384, 385, 386, 387, 388, 466,\n",
    "                  263, 249, 390, 373, 374, 380, 381, 382]\n",
    "\n",
    "            il = [78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "                  308, 324, 318, 402, 317, 14, 87, 178, 88, 95]\n",
    "            ol = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n",
    "                  291, 375, 321, 405, 314, 17, 84, 181, 91, 146]\n",
    "\n",
    "            while True:\n",
    "                success, frame = cap.read()\n",
    "                if not success:     # If no frame is detected then stop\n",
    "                    break\n",
    "                if videos_dir.split('.')[-1] == \"mp4\":\n",
    "                    frame = cv2.resize(frame, (1600, 900))\n",
    "                frame_count += 1\n",
    "                frame = cv2.flip(frame, 1)\n",
    "                results = faceMesh.process(frame)  # Detect faces\n",
    "\n",
    "                if results.multi_face_landmarks:\n",
    "                    # Consider only 1st detected face\n",
    "                    face = results.multi_face_landmarks[0]\n",
    "                    face_landmarks = self.landmarkCoordinates(\n",
    "                        face.landmark, frame)   # Get facial landmarks\n",
    "\n",
    "                    left_eye_ratio = self.aspect_ratio(\n",
    "                        le, face_landmarks)  # 7vertical 1horizontal\n",
    "                    right_eye_ratio = self.aspect_ratio(\n",
    "                        re, face_landmarks)  # 7v 1h\n",
    "                    # Calculate eye aspect ratio\n",
    "                    eye_aspect_ratio = (left_eye_ratio + right_eye_ratio) / 2\n",
    "\n",
    "                    inner_lip_ratio = self.aspect_ratio(\n",
    "                        il, face_landmarks)  # 9v  1h\n",
    "                    outter_lip_ratio = self.aspect_ratio(\n",
    "                        ol, face_landmarks)  # 9v 1h\n",
    "                    # Calculate mouth aspect ratio\n",
    "                    mouth_aspect_ratio = (\n",
    "                        inner_lip_ratio + outter_lip_ratio) / 2\n",
    "\n",
    "                    max_ear = max(max_ear, eye_aspect_ratio)\n",
    "                    min_ear = min(min_ear, eye_aspect_ratio)\n",
    "                    diff = max_ear - min_ear\n",
    "                    # Calculate threshold eye aspect ratio\n",
    "                    threshold_ear = min_ear + diff * per / 100\n",
    "\n",
    "                    if eye_aspect_ratio < threshold_ear:\n",
    "                        eye_close_count += 1\n",
    "                    else:\n",
    "                        eye_close_count = 0\n",
    "\n",
    "                    if mouth_aspect_ratio > threshold_mar:\n",
    "                        mouth_open_count += 1\n",
    "                    else:\n",
    "                        mouth_open_count = 0\n",
    "\n",
    "                    if eye_close_count < max_frame_count and mouth_open_count < max_frame_count:\n",
    "                        worksheet.write('B'+str(frame_count+1), 0)\n",
    "                        cv2.putText(frame, \"Active :)\", (250, 50),\n",
    "                                    font, 1, (31, 163, 21))\n",
    "\n",
    "                    else:\n",
    "                        worksheet.write('B'+str(frame_count+1), 1)\n",
    "                        cv2.putText(frame, \"Drowsy!\", (250, 50),\n",
    "                                    font, 1, (255, 0, 0))\n",
    "                else:\n",
    "                    worksheet.write('B'+str(frame_count+1), 0)\n",
    "\n",
    "                worksheet.write('A'+str(frame_count+1), frame_count)\n",
    "                cv2.imshow(\"Annotate Video Using Algorithm\",\n",
    "                           frame)  # Display frame\n",
    "\n",
    "                key = cv2.waitKey(1)    # Press Esc to exit\n",
    "                if key == 27:\n",
    "                    break\n",
    "\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            workbook.close()\n",
    "\n",
    "\n",
    "obj = AnnotVideoAlgo()\n",
    "obj.AnnotateVideoAlgo(\"Testing Dataset\\\\Videos\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create combined result file to calculate accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from math import hypot\n",
    "\n",
    "\n",
    "class Predict:\n",
    "\n",
    "    def aspect_ratio(self, landmark_list, face_landmarks):   # Calculate Aspect Ratio\n",
    "        n = len(landmark_list)\n",
    "\n",
    "        # Calculate horizontal length\n",
    "        left_point = face_landmarks[landmark_list[0]]  # (x, y)\n",
    "        right_point = face_landmarks[landmark_list[n//2]]\n",
    "        hor_length = hypot(\n",
    "            (left_point[0] - right_point[0]), (left_point[1] - right_point[1]))\n",
    "\n",
    "        top = list()    # Co-ordinates of the upper part\n",
    "        bottom = list()  # Co-ordinates of the lower part\n",
    "\n",
    "        for i in range(1, n//2):\n",
    "            top.append(face_landmarks[landmark_list[i]])\n",
    "            bottom.append(face_landmarks[landmark_list[-1*i]])\n",
    "\n",
    "        ver_lengths = list()\n",
    "        for i in range(len(top)):   # Calculate vertical lengths\n",
    "            d = hypot((top[i][0] - bottom[i][0]), (top[i][1] - bottom[i][1]))\n",
    "            ver_lengths.append(d)\n",
    "\n",
    "        s = len(ver_lengths)\n",
    "        ratio = sum(ver_lengths) / (s * hor_length)  # Calculate aspect ratio\n",
    "        return ratio\n",
    "\n",
    "    def landmarkCoordinates(self, facelandmarks, image):\n",
    "        coord = list()\n",
    "        ih, iw, ic = image.shape  # image height, image width, image channels\n",
    "        for lm in facelandmarks:\n",
    "            x, y = int(lm.x*iw), int(lm.y*ih)\n",
    "            coord.append((x, y))\n",
    "        return coord\n",
    "\n",
    "    def pred(self, dir1, dir2):\n",
    "\n",
    "        data_present = pd.read_excel(\"Testing Dataset\\\\Results.xlsx\")[\n",
    "            \"Video\"].unique()\n",
    "\n",
    "        for (f1, f2) in zip(os.listdir(dir1), os.listdir(dir2)):\n",
    "            file_name = os.fsdecode(f1)\n",
    "            annot_name = os.fsdecode(f2)\n",
    "\n",
    "            if file_name in data_present:\n",
    "                print(\"Data for video\", file_name, \"is already present.\")\n",
    "                continue\n",
    "\n",
    "            if file_name.split('.')[0] == annot_name.split('.')[0]:\n",
    "                video_path = os.path.join(dir1, file_name)\n",
    "                annot_path = os.path.join(dir2, annot_name)\n",
    "\n",
    "                cap = cv2.VideoCapture(video_path)\n",
    "                frame_count = 0\n",
    "\n",
    "                mpFaceMesh = mp.solutions.face_mesh\n",
    "                faceMesh = mpFaceMesh.FaceMesh()\n",
    "\n",
    "                eye_close_count = 0\n",
    "                mouth_open_count = 0\n",
    "                font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "                max_ear = 0\n",
    "                min_ear = 1\n",
    "                per = 40\n",
    "                threshold_ear = 0.25\n",
    "                threshold_mar = 0.35\n",
    "                max_frame_count = 20\n",
    "\n",
    "                le = [33, 246, 161, 160, 159, 158, 157, 173,\n",
    "                      133, 155, 154, 153, 145, 144, 163, 7]\n",
    "                re = [362, 398, 384, 385, 386, 387, 388, 466,\n",
    "                      263, 249, 390, 373, 374, 380, 381, 382]\n",
    "\n",
    "                il = [78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "                      308, 324, 318, 402, 317, 14, 87, 178, 88, 95]\n",
    "                ol = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n",
    "                      291, 375, 321, 405, 314, 17, 84, 181, 91, 146]\n",
    "\n",
    "                df = pd.read_excel(annot_path)\n",
    "                actual = df[\"Drowsy Status\"].to_list()\n",
    "                predicted = list()\n",
    "\n",
    "                while True:\n",
    "                    success, frame = cap.read()\n",
    "                    if not success:     # If no frame is detected then stop\n",
    "                        break\n",
    "                    if video_path.split('.')[-1] == \"mp4\":\n",
    "                        frame = cv2.resize(frame, (1600, 900))\n",
    "                    frame_count += 1\n",
    "                    frame = cv2.flip(frame, 1)\n",
    "                    results = faceMesh.process(frame)  # Detect faces\n",
    "\n",
    "                    if results.multi_face_landmarks:\n",
    "                        # Consider only 1st detected face\n",
    "                        face = results.multi_face_landmarks[0]\n",
    "                        face_landmarks = self.landmarkCoordinates(\n",
    "                            face.landmark, frame)   # Get facial landmarks\n",
    "\n",
    "                        left_eye_ratio = self.aspect_ratio(\n",
    "                            le, face_landmarks)  # 7vertical 1horizontal\n",
    "                        right_eye_ratio = self.aspect_ratio(\n",
    "                            re, face_landmarks)  # 7v 1h\n",
    "                        # Calculate eye aspect ratio\n",
    "                        eye_aspect_ratio = (\n",
    "                            left_eye_ratio + right_eye_ratio) / 2\n",
    "\n",
    "                        inner_lip_ratio = self.aspect_ratio(\n",
    "                            il, face_landmarks)  # 9v  1h\n",
    "                        outter_lip_ratio = self.aspect_ratio(\n",
    "                            ol, face_landmarks)  # 9v 1h\n",
    "                        # Calculate mouth aspect ratio\n",
    "                        mouth_aspect_ratio = (\n",
    "                            inner_lip_ratio + outter_lip_ratio) / 2\n",
    "\n",
    "                        max_ear = max(max_ear, eye_aspect_ratio)\n",
    "                        min_ear = min(min_ear, eye_aspect_ratio)\n",
    "                        diff = max_ear - min_ear\n",
    "                        # Calculate threshold eye aspect ratio\n",
    "                        threshold_ear = min_ear + diff * per / 100\n",
    "\n",
    "                        if eye_aspect_ratio < threshold_ear:\n",
    "                            eye_close_count += 1\n",
    "                        else:\n",
    "                            eye_close_count = 0\n",
    "\n",
    "                        if mouth_aspect_ratio > threshold_mar:\n",
    "                            mouth_open_count += 1\n",
    "                        else:\n",
    "                            mouth_open_count = 0\n",
    "\n",
    "                        if eye_close_count < max_frame_count and mouth_open_count < max_frame_count:\n",
    "                            predicted.append(0)\n",
    "                            cv2.putText(frame, \"Predicted State => Active :)\",\n",
    "                                        (380, 50), font, 0.5, (31, 163, 21))\n",
    "                        else:\n",
    "                            predicted.append(1)\n",
    "                            cv2.putText(frame, \"Predicted State => Drowsy!\",\n",
    "                                        (380, 50), font, 0.5, (255, 0, 0))\n",
    "\n",
    "                        if actual[len(predicted)-1] == 1:\n",
    "                            cv2.putText(frame, \"Actual State => Drowsy!\",\n",
    "                                        (10, 50), font, 0.5, (255, 0, 0))\n",
    "                        else:\n",
    "                            cv2.putText(frame, \"Actual State => Active :)\",\n",
    "                                        (10, 50), font, 0.5, (31, 163, 21))\n",
    "\n",
    "                    else:\n",
    "                        predicted.append(0)\n",
    "\n",
    "                    # Display frame\n",
    "                    cv2.imshow(\n",
    "                        \"Create combined result file to calculate accuracy\", frame)\n",
    "\n",
    "                    key = cv2.waitKey(1)    # Press Esc to exit\n",
    "                    if key == 27:\n",
    "                        break\n",
    "\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "\n",
    "                if len(actual) == len(predicted):\n",
    "                    df2 = pd.DataFrame({\"Video\": file_name, \"Frame Number\": list(\n",
    "                        range(1, frame_count+1)), \"Actual\": actual, \"Predicted\": predicted})\n",
    "                    workbook = openpyxl.load_workbook(\n",
    "                        'Testing Dataset\\Results.xlsx')\n",
    "                    worksheet = workbook['Sheet1']\n",
    "                    data = df2.values.tolist()\n",
    "                    for row in data:\n",
    "                        worksheet.append(row)\n",
    "                    workbook.save('Testing Dataset\\Results.xlsx')\n",
    "                else:\n",
    "                    print(\"Error in video\", file_name)\n",
    "            else:\n",
    "                print(\"Error in video\", file_name)\n",
    "\n",
    "\n",
    "obj = Predict()\n",
    "obj.pred(\"Testing Dataset\\\\Videos\\\\\", \"Testing Dataset\\\\Annotation\\\\\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Performace of Model using One Video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# import the necessary libraries\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from math import hypot\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "class Test:\n",
    "\n",
    "    def aspect_ratio(self, landmark_list, face_landmarks):   # Calculate Aspect Ratio\n",
    "        n = len(landmark_list)\n",
    "\n",
    "        # Calculate horizontal length\n",
    "        left_point = face_landmarks[landmark_list[0]]  # (x, y)\n",
    "        right_point = face_landmarks[landmark_list[n//2]]\n",
    "        hor_length = hypot(\n",
    "            (left_point[0] - right_point[0]), (left_point[1] - right_point[1]))\n",
    "\n",
    "        top = list()    # Co-ordinates of the upper part\n",
    "        bottom = list()  # Co-ordinates of the lower part\n",
    "\n",
    "        for i in range(1, n//2):\n",
    "            top.append(face_landmarks[landmark_list[i]])\n",
    "            bottom.append(face_landmarks[landmark_list[-1*i]])\n",
    "\n",
    "        ver_lengths = list()\n",
    "        for i in range(len(top)):   # Calculate vertical lengths\n",
    "            d = hypot((top[i][0] - bottom[i][0]), (top[i][1] - bottom[i][1]))\n",
    "            ver_lengths.append(d)\n",
    "\n",
    "        s = len(ver_lengths)\n",
    "        ratio = sum(ver_lengths) / (s * hor_length)  # Calculate aspect ratio\n",
    "        return ratio\n",
    "\n",
    "    def landmarkCoordinates(self, facelandmarks, image):\n",
    "        coord = list()\n",
    "        ih, iw, ic = image.shape  # image height, image width, image channels\n",
    "        for lm in facelandmarks:\n",
    "            x, y = int(lm.x*iw), int(lm.y*ih)\n",
    "            coord.append((x, y))\n",
    "        return coord\n",
    "\n",
    "    def testing(self, video_path):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_count = 0\n",
    "\n",
    "        mpFaceMesh = mp.solutions.face_mesh\n",
    "        faceMesh = mpFaceMesh.FaceMesh()\n",
    "\n",
    "        eye_close_count = 0\n",
    "        mouth_open_count = 0\n",
    "        font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "        max_ear = 0\n",
    "        min_ear = 1\n",
    "        per = 40\n",
    "        threshold_ear = 0.25\n",
    "        threshold_mar = 0.35\n",
    "        max_frame_count = 20\n",
    "\n",
    "        le = [33, 246, 161, 160, 159, 158, 157, 173,\n",
    "              133, 155, 154, 153, 145, 144, 163, 7]\n",
    "        re = [362, 398, 384, 385, 386, 387, 388, 466,\n",
    "              263, 249, 390, 373, 374, 380, 381, 382]\n",
    "\n",
    "        il = [78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "              308, 324, 318, 402, 317, 14, 87, 178, 88, 95]\n",
    "        ol = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n",
    "              291, 375, 321, 405, 314, 17, 84, 181, 91, 146]\n",
    "\n",
    "        n = video_path.split(\"\\\\\")[-1]\n",
    "        n = n.split(\".\")[0]\n",
    "        df = pd.read_excel(\"Testing Dataset\\\\Annotation\\\\\" + n + \".xlsx\")\n",
    "        actual = df[\"Drowsy Status\"].to_list()\n",
    "        predicted = list()\n",
    "\n",
    "        while True:\n",
    "            success, frame = cap.read()\n",
    "            if not success:     # If no frame is detected then stop\n",
    "                break\n",
    "            if video_path.split('.')[-1] == \"mp4\":\n",
    "                frame = cv2.resize(frame, (1600, 900))\n",
    "            frame_count += 1\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            results = faceMesh.process(frame)  # Detect faces\n",
    "\n",
    "            if results.multi_face_landmarks:\n",
    "                # Consider only 1st detected face\n",
    "                face = results.multi_face_landmarks[0]\n",
    "                face_landmarks = self.landmarkCoordinates(\n",
    "                    face.landmark, frame)   # Get facial landmarks\n",
    "\n",
    "                left_eye_ratio = self.aspect_ratio(\n",
    "                    le, face_landmarks)  # 7vertical 1horizontal\n",
    "                right_eye_ratio = self.aspect_ratio(\n",
    "                    re, face_landmarks)  # 7v 1h\n",
    "                # Calculate eye aspect ratio\n",
    "                eye_aspect_ratio = (left_eye_ratio + right_eye_ratio) / 2\n",
    "\n",
    "                inner_lip_ratio = self.aspect_ratio(\n",
    "                    il, face_landmarks)  # 9v  1h\n",
    "                outter_lip_ratio = self.aspect_ratio(\n",
    "                    ol, face_landmarks)  # 9v 1h\n",
    "                # Calculate mouth aspect ratio\n",
    "                mouth_aspect_ratio = (inner_lip_ratio + outter_lip_ratio) / 2\n",
    "\n",
    "                max_ear = max(max_ear, eye_aspect_ratio)\n",
    "                min_ear = min(min_ear, eye_aspect_ratio)\n",
    "                diff = max_ear - min_ear\n",
    "                # Calculate threshold eye aspect ratio\n",
    "                threshold_ear = min_ear + diff * per / 100\n",
    "\n",
    "                if eye_aspect_ratio < threshold_ear:\n",
    "                    eye_close_count += 1\n",
    "                else:\n",
    "                    eye_close_count = 0\n",
    "\n",
    "                if mouth_aspect_ratio > threshold_mar:\n",
    "                    mouth_open_count += 1\n",
    "                else:\n",
    "                    mouth_open_count = 0\n",
    "\n",
    "                if eye_close_count < max_frame_count and mouth_open_count < max_frame_count:\n",
    "                    predicted.append(0)\n",
    "                    cv2.putText(frame, \"Predicted State => Active :)\",\n",
    "                                (380, 50), font, 0.5, (31, 163, 21))\n",
    "                else:\n",
    "                    predicted.append(1)\n",
    "                    cv2.putText(frame, \"Predicted State => Drowsy!\",\n",
    "                                (380, 50), font, 0.5, (255, 0, 0))\n",
    "\n",
    "                if actual[len(predicted)-1] == 1:\n",
    "                    cv2.putText(frame, \"Actual State => Drowsy!\",\n",
    "                                (10, 50), font, 0.5, (255, 0, 0))\n",
    "                else:\n",
    "                    cv2.putText(frame, \"Actual State => Active :)\",\n",
    "                                (10, 50), font, 0.5, (31, 163, 21))\n",
    "\n",
    "            else:\n",
    "                predicted.append(0)\n",
    "\n",
    "            cv2.imshow(\"Testing Performace of Model using One Video\",\n",
    "                       frame)  # Display frame\n",
    "\n",
    "            key = cv2.waitKey(1)    # Press Esc to exit\n",
    "            if key == 27:\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        if len(actual) != len(predicted):\n",
    "            print(\"Error in\", video_path.split(\"\\\\\")[-1])\n",
    "            return\n",
    "\n",
    "        cm = confusion_matrix(actual, predicted)\n",
    "        plt.figure()\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.show()\n",
    "\n",
    "        # Accuracy Score = (TP + TN) / (TP + FN + TN + FP)\n",
    "        print('Accuracy:', round(accuracy_score(actual, predicted), 5))\n",
    "\n",
    "        # Precision Score = TP / (FP + TP)\n",
    "        print('Precision:', round(precision_score(actual, predicted), 5))\n",
    "\n",
    "        # Recall Score = TP / (FN + TP)\n",
    "        print('Recall:', round(recall_score(actual, predicted), 5))\n",
    "\n",
    "        # F1 Score = 2 * Precision Score * Recall Score / (Precision Score + Recall Score)\n",
    "        print('F1 Score:', round(f1_score(actual, predicted), 5))\n",
    "\n",
    "\n",
    "obj = Test()\n",
    "video_path = input(\"Enter path of video: \")\n",
    "obj.testing(video_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Overall Accuracy of the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95472\n",
      "Precision: 0.98278\n",
      "Recall: 0.74723\n",
      "F1 Score: 0.84897\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "df = pd.read_excel(\"Testing Dataset\\\\Results.xlsx\")\n",
    "actual = df[\"Actual\"].to_list()\n",
    "predicted = df[\"Predicted\"].to_list()\n",
    "\n",
    "if len(actual) != len(predicted):\n",
    "    print(\"Error in data\")\n",
    "    exit(0)\n",
    "\n",
    "cm = confusion_matrix(actual, predicted)\n",
    "plt.figure()\n",
    "plt.title(\"Confusion Matrix\")\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# Accuracy Score = (TP + TN) / (TP + FN + TN + FP)\n",
    "print('Accuracy:', round(accuracy_score(actual, predicted), 5))\n",
    "\n",
    "# Precision Score = TP / (FP + TP)\n",
    "print('Precision:', round(precision_score(actual, predicted), 5))\n",
    "\n",
    "# Recall Score = TP / (FN + TP)\n",
    "print('Recall:', round(recall_score(actual, predicted), 5))\n",
    "\n",
    "# F1 Score = 2 * Precision Score * Recall Score / (Precision Score + Recall Score)\n",
    "print('F1 Score:', round(f1_score(actual, predicted), 5))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete data of a video from Results.xlsx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "video = input(\"Enter name of video (with extension): \")\n",
    "df = pd.read_excel(\"Testing Dataset\\\\Results.xlsx\")\n",
    "df = df[df[\"Video\"] != video]\n",
    "\n",
    "df.to_excel(\"Testing Dataset\\\\Results.xlsx\", index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete all data from Results.xlsx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"Video\": [], \"Frame Number\": [],\n",
    "                  \"Actual\": [], \"Predicted\": []})\n",
    "df.to_excel(\"Testing Dataset\\\\Results.xlsx\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
